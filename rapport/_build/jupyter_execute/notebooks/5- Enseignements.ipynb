{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlike-spokesman",
   "metadata": {},
   "source": [
    "# Enseignements et pistes d'amélioration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-polyester",
   "metadata": {},
   "source": [
    "Plusieurs modèle ont été testés. Le modèle champion est un XGBoost optimisé s'appuyant sur une combinaison de features créées à partir de modèles pré entrainé dont roBERTa tweet.\n",
    "Ce modèle permet d'atteindre un f1 macro de **76%** sur le jeu test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "increasing-alloy",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metropolitan-vegetarian",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>f1_macro_val</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roBERTa_xgb_opti_</td>\n",
       "      <td>0.759147</td>\n",
       "      <td>0.759953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roBERTa_Blob_Vader_RF_opti_</td>\n",
       "      <td>0.756699</td>\n",
       "      <td>0.750216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roBERTa_RF_opti_</td>\n",
       "      <td>0.746630</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfIdf_LR_opti_modif_seuil</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_TfIdf_RF_prepro_</td>\n",
       "      <td>0.707919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base_TfIdf_RF_prepro_opti_</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roBERTa_RF_</td>\n",
       "      <td>0.705912</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TfIdf_LR_opti_</td>\n",
       "      <td>0.699877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TfIdf_LR_prepro_opti_</td>\n",
       "      <td>0.698565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base_TfIdf_RF_</td>\n",
       "      <td>0.669789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        modèle  f1_macro_val  f1_macro_test\n",
       "0            roBERTa_xgb_opti_      0.759147       0.759953\n",
       "1  roBERTa_Blob_Vader_RF_opti_      0.756699       0.750216\n",
       "2             roBERTa_RF_opti_      0.746630            NaN\n",
       "3    TfIdf_LR_opti_modif_seuil      0.709477            NaN\n",
       "4        base_TfIdf_RF_prepro_      0.707919            NaN\n",
       "5   base_TfIdf_RF_prepro_opti_      0.706432            NaN\n",
       "6                  roBERTa_RF_      0.705912            NaN\n",
       "7               TfIdf_LR_opti_      0.699877            NaN\n",
       "8        TfIdf_LR_prepro_opti_      0.698565            NaN\n",
       "9               base_TfIdf_RF_      0.669789            NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_fin2 = pd.read_parquet('/mnt/data/processed/res_fin2.gzip')\n",
    "res_fin2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-commons",
   "metadata": {},
   "source": [
    "Ce projet a été une constant source d'étonnement.\n",
    "\n",
    "Le fait de disposer de 3 classes à prédire a été un élément complexifiant par rapport au cas binaire (pas de courbe ROC générale). On devient beaucoup plus dépendant des chiffres.\n",
    "\n",
    "Après la découverte de [twitter-roberta-base-sentiment](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment), je pensais que le sujet serait plié. Après tout ce modèle a été entrainé explicitement pour ce cas (58 millions de tweets, en anglais et optimisé pour l'analyse de sentiments). Je pensais voir le f1 macro s'envoler, ce qui n'a pas été le cas. Le modèle a bien aidé, mais le gain est resté modeste (6 points de f1 macro par rapport aux approches fréquentistes classiques).\n",
    "\n",
    "Au final en analysant les fausses prédictions, on réalise que la labelisation de plusieurs tweets laisse songeur.\n",
    "Ceci met en lumière le fait que l'appréciation de la tonalité n'est pas toujours évidente et que des erreurs humaines peuvent en plus se glisser.\n",
    "Si ce phénomène existe déjà pour les catégories extrèmes (`positif` et `négatif`) on imagine la sensibilité pour la classe générique `neutre`...\n",
    "\n",
    "Par ailleurs rien n'indique que la stratégie de labellisation utilisé dans ce cas corresponde à celle utilisée pour le pré entrainement de roBERTa tweet.\n",
    "\n",
    "Deux pistes auraient pu être explorées pour améliorer la performance :\n",
    "- véritablement réentrainer la dernière couche de BERT sur le jeu de donénes pour apprendre la logique de classification\n",
    "- potentiellement modéliser le sujet discuté dans les twwets et le rajouter comme feature. On avait en effet vu que les tweets positifs par exemple se rapportaient principalement à la fête des mère et au `star wars day`\n",
    "\n",
    "Enfin ce sujet a été l'occasion de se frotter à plusieurs difficultés techniques liées principalement :\n",
    "- à l'utilisation de ressources GPU depuis docker\n",
    "- à l'utilisation des GPU pour XGBoost (non pris en compte par défaut)\n",
    "- aux pipelines sklearn, pratiques mais pas toujousr compatibles avec les packages (ex SHAP) et nécessitant souvent des créations de classes ad-hoc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}