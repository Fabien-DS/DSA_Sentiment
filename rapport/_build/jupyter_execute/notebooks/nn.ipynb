{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fluid-component",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "**TD DSA 2021 de Antoine Ly   -   rapport de Fabien Faivre**\n",
    "-------------------------     -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-reynolds",
   "metadata": {},
   "source": [
    "# Un dernier Essai : BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-order",
   "metadata": {},
   "source": [
    "Après avoir utilisé directement les modèles préentrainé, je souhaitais essayer d'ajuster véritablement un modèle de Deep Learning.\n",
    "\n",
    "J'ai alors trouvé un article sur `medium` présentant une telle adaptation :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-techno",
   "metadata": {},
   "source": [
    "source : https://scottmduda.medium.com/fine-tuning-language-models-for-sentiment-analysis-91db72396549\n",
    "\n",
    "github : https://github.com/dontmindifiduda/financial_statement_sentiment_analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-reset",
   "metadata": {},
   "source": [
    "La logique consiste à aller chercher un modèle préentrainé sur HuggingFace. Ici trous variantes sont testées :\n",
    "\n",
    "- `BERT` : le modèle de référence de l'encodage bidirectionnel initialement publié par Google\n",
    "- `DistilBERT` : la version allégée de `BERT` pour des performances a priori comparables\n",
    "- `RoBERTa` : la variante de Facebook de `BERT` renonçant à l'objectif de prédiction de la phrase suivante et ayant été entraîné avec plus de données et des séquences d'apprentissage plus longues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "religious-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, DistilBertTokenizer, RobertaModel, RobertaTokenizer\n",
    "from transformers import AutoConfig, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-tolerance",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bridal-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Importe les données\n",
    "\n",
    "#df\n",
    "df_train=pd.read_parquet('/mnt/data/interim/df_train.gzip')\n",
    "df_val=pd.read_parquet('/mnt/data/interim/df_val.gzip')\n",
    "df_test=pd.read_parquet('/mnt/data/interim/df_test.gzip')\n",
    "\n",
    "#X\n",
    "X_train=pd.read_parquet('/mnt/data/interim/X_train.gzip')\n",
    "X_val=pd.read_parquet('/mnt/data/interim/X_val.gzip')\n",
    "X_test=pd.read_parquet('/mnt/data/interim/X_test.gzip')\n",
    "\n",
    "X_train_prepro=pd.read_parquet('/mnt/data/interim/X_train_prepro.gzip')\n",
    "X_val_prepro=pd.read_parquet('/mnt/data/interim/X_val_prepro.gzip')\n",
    "X_test_prepro=pd.read_parquet('/mnt/data/interim/X_test_prepro.gzip')\n",
    "\n",
    "#y\n",
    "y_train=pd.read_parquet('/mnt/data/interim/y_train.gzip')\n",
    "y_val=pd.read_parquet('/mnt/data/interim/y_val.gzip')\n",
    "y_test=pd.read_parquet('/mnt/data/interim/y_test.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adapted-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_fin2 = pd.read_parquet('/mnt/data/processed/res_fin2.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-discrimination",
   "metadata": {},
   "source": [
    "## Définition du Device à utiliser et fixation de la graîne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "representative-client",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4aa41a9330>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "RANDOM_SEED = 73\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driving-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_val, df_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "attractive-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['num_char'] = df['text'].apply(len)\n",
    "df['num_words'] = df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dramatic-coupon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/mnt/rapport/_build/jupyter_execute/notebooks/nn_13_0.png"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.countplot(x='sentiment', data=df)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Nombre de tweets')\n",
    "plt.title('Nombre de tweets par setiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "structural-active",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plus long tweet :  33 mots.\n"
     ]
    }
   ],
   "source": [
    "print('Plus long tweet : ', df['num_words'].max(), 'mots.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "referenced-suspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet le plus court :  1 mots.\n"
     ]
    }
   ],
   "source": [
    "print('Tweet le plus court : ', df['num_words'].min(), 'mots.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-radiation",
   "metadata": {},
   "source": [
    "## Exploration pour l'analyse de sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-relative",
   "metadata": {},
   "source": [
    "### Code générique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "victorian-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 64\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 3\n",
    "EPOCHS = 5\n",
    "DROPOUT_PROB = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "NFOLDS = 10\n",
    "LEARNING_RATE = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "civil-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-confusion",
   "metadata": {},
   "source": [
    "La classe suivante permet de charger les données et tokeniser les tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "provincial-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tweets, labels, tokenizer, max_length):\n",
    "        self.tweets = tweets\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.tweets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        tweet = str(self.tweets[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            add_special_tokens=True, \n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'  \n",
    "        ) \n",
    "        \n",
    "        return {\n",
    "            'tweet_text': tweet,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-forward",
   "metadata": {},
   "source": [
    "Transforme les jeux de données. Les données sont tronquées au delà de `MAX_LENGTH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "annual-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, tokenizer, max_length):\n",
    "    ds = TweetDataset(tweets=df['text'].to_numpy(),\n",
    "                          labels=df['sentiment'].to_numpy(),\n",
    "                          tokenizer=tokenizer,\n",
    "                          max_length=max_length)\n",
    "    return ds\n",
    "\n",
    "def create_dataloader(ds, batch_size):\n",
    "    return DataLoader(ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-midnight",
   "metadata": {},
   "source": [
    "Le code suivant crée deux variantes d'évaluation de modèles :\n",
    "\n",
    "- `single model performance` : analyse directement les résultats d'un unique modèle\n",
    "\n",
    "- `cv_ensemble_performance` : crée les prédictions d'un ensemble modèle. Utilisé en liaison avec l'analyse 10 fold : les modèles sur chaque fold sont considérés comme indépendants et combiné pour déterminer la prédiction finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "agreed-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_ensemble_performance(preds, labels):\n",
    "    preds = np.array(preds)\n",
    "    summed = np.sum(preds, axis=0)\n",
    "    preds = np.argmax(summed, axis=1)\n",
    "    print(confusion_matrix(y_true=labels, y_pred=preds))\n",
    "    print('')\n",
    "    print(classification_report(y_true=labels, y_pred=preds, digits=3, target_names=le.classes_))\n",
    "    \n",
    "def single_model_performance(preds, labels):\n",
    "    print(confusion_matrix(y_true=labels, y_pred=preds))\n",
    "    print('')\n",
    "    print(classification_report(y_true=labels, y_pred=preds, digits=3, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-exploration",
   "metadata": {},
   "source": [
    "`train_model` entraine le modèle sur chaque batch du jeu de données (extraits par le DalaLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "veterinary-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, data_loader, loss_function, \n",
    "                optimizer, scheduler, n_examples):\n",
    "    \n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_preds = 0\n",
    "    complete_preds = []\n",
    "    complete_labels = []\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        complete_preds.append(preds.data.cpu().numpy().tolist())\n",
    "        complete_labels.append(labels.data.cpu().numpy().tolist())\n",
    "        correct_preds += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    complete_preds_flat = [x for y in complete_preds for x in y]\n",
    "    complete_labels_flat = [x for y in complete_labels for x in y]\n",
    "    acc_score = accuracy_score(y_true=complete_labels_flat, \n",
    "                             y_pred=complete_preds_flat)\n",
    "    return acc_score, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-upgrade",
   "metadata": {},
   "source": [
    "`eval_model` : évalue un modèle sur un jeu de test pour chaque batch du jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "governing-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, device, data_loader, loss_function, n_examples):\n",
    "    model = model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct_preds = 0\n",
    "    complete_preds = []\n",
    "    complete_labels = []\n",
    "    complete_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for item in data_loader:\n",
    "            input_ids = item['input_ids'].to(device)\n",
    "            attention_mask = item['attention_mask'].to(device)\n",
    "            labels = item['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask)\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            \n",
    "            correct_preds += torch.sum(preds == labels)\n",
    "            complete_preds.append(preds.data.cpu().numpy().tolist())\n",
    "            complete_labels.append(labels.data.cpu().numpy().tolist())\n",
    "            complete_outputs.append(outputs.tolist())\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        accuracy = correct_preds.double() / n_examples\n",
    "        complete_preds_flat = [x for y in complete_preds for x in y]\n",
    "        complete_labels_flat = [x for y in complete_labels for x in y]\n",
    "        complete_outputs_flat = [x for y in complete_outputs for x in y]\n",
    "\n",
    "        acc_score = accuracy_score(y_true=complete_labels_flat, \n",
    "                             y_pred=complete_preds_flat)\n",
    "        \n",
    "        return_items = (acc_score, \n",
    "                        np.mean(losses),\n",
    "                        complete_labels_flat,\n",
    "                        complete_preds_flat, \n",
    "                        complete_outputs_flat)\n",
    "        \n",
    "        return return_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-rainbow",
   "metadata": {},
   "source": [
    "`plot_cm` permet de tracer la matrice de confusion du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "golden-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_test, y_pred, target_names=[-1, 0, 1], \n",
    "            figsize=(5,3)):\n",
    "    \"\"\"Create a labelled confusion matrix plot.\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='BuGn', cbar=False, \n",
    "                ax=ax)\n",
    "    ax.set_title('Confusion matrix')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_xticklabels(target_names)\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_yticklabels(target_names, \n",
    "                       fontdict={'verticalalignment': 'center'});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-employment",
   "metadata": {},
   "source": [
    "On initialise MLFlow pour pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intensive-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pytorch\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-vegetation",
   "metadata": {},
   "source": [
    "`train_fold` permet d'entrainer un modèle sur un unique fold. Les résiltats sont stockés dans MLFlow. Les résultats sont évalués à l'issue de chaque EPOCH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "double-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(mlf_XP, xp_name_iter, epochs, model, device, train_dataloader, \n",
    "               val_dataloader, test_dataloader, loss_fn, optimizer, \n",
    "               scheduler, model_save_name, n_train, n_val, single_model=True):\n",
    "    \n",
    "    \n",
    "    mlflow.set_experiment(mlf_XP)\n",
    "\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = defaultdict(list)\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        run_name = xp_name_iter + '_' + str(epoch+1)\n",
    "        with mlflow.start_run(run_name = run_name):\n",
    "            epoch_start_time = time.time()\n",
    "            print('Epoch ', epoch+1, '/', epochs)\n",
    "            print('-'*50)\n",
    "\n",
    "            training_output = train_model(model, \n",
    "                                          device, \n",
    "                                          train_dataloader, \n",
    "                                          loss_fn, \n",
    "                                          optimizer, \n",
    "                                          scheduler, \n",
    "                                          n_train)\n",
    "\n",
    "            train_acc, train_loss = training_output\n",
    "\n",
    "            val_output = eval_model(model, \n",
    "                                    device, \n",
    "                                    val_dataloader, \n",
    "                                    loss_fn, \n",
    "                                    n_val)\n",
    "\n",
    "            val_acc, val_loss, _, val_preds, val_outputs = val_output\n",
    "\n",
    "            history['train_accuracy'].append(train_acc)\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_accuracy'].append(val_acc)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_preds'].append(val_preds)\n",
    "            \n",
    "            mlflow.log_metrics({'epoch': epoch, 'train_acc' : train_acc, 'train_loss': train_loss, 'val_acc': val_acc, 'val_loss' : val_loss })\n",
    "            \n",
    "            mlflow.pytorch.log_model(model, run_name, conda_env='/mnt/configs/conda.yml')\n",
    "            \n",
    "            if val_acc > best_accuracy:\n",
    "                torch.save(model.state_dict(), model_save_name)\n",
    "                best_accuracy = val_acc\n",
    "                best_preds = val_preds\n",
    "                best_outputs = val_outputs\n",
    "                best_epoch = epoch\n",
    "                \n",
    "\n",
    "            print('Train Loss: ', \n",
    "                  train_loss, \n",
    "                  ' | ', \n",
    "                  'Train Accuracy: ', \n",
    "                  train_acc)\n",
    "            print('Val Loss: ', \n",
    "                  val_loss, \n",
    "                  ' | ', \n",
    "                  'Val Accuracy: ', \n",
    "                  val_acc)\n",
    "            elapsed_time = format_time(time.time() - epoch_start_time)\n",
    "            print('Epoch Train Time: ', \n",
    "                  elapsed_time)\n",
    "            print('\\n')\n",
    "            \n",
    "            mlflow.set_tag(key=\"elapsed_time\", value=elapsed_time)   \n",
    "\n",
    "    print('Finished Training.')   \n",
    "    print('Fold Train Time: ', format_time(time.time() - start_time))\n",
    "    print('\\n')\n",
    "                  \n",
    "    if single_model:\n",
    "        test_acc, test_loss, test_actuals, test_preds, test_outputs = eval_model(model, \n",
    "                                                    device, \n",
    "                                                    test_dataloader, \n",
    "                                                    loss_function, \n",
    "                                                    len(df_test))\n",
    "\n",
    "        single_model_performance(test_preds, df_test['sentiment'].values)\n",
    "        plot_cm(test_actuals, test_preds)\n",
    "        f1_macro_test = f1_score(test_actuals, test_preds, average='macro')\n",
    "        run_name = xp_name_iter + '_best'\n",
    "        with mlflow.start_run(run_name = run_name):\n",
    "            mlflow.log_metrics({'train_acc' : history['train_accuracy'][epoch], 'train_loss': history['train_accuracy'][epoch], 'val_acc': history['val_accuracy'][epoch], 'val_loss' : history['train_accuracy'][epoch], 'test_acc': test_acc, 'test_loss': test_loss, 'f1_test':f1_macro_test})\n",
    "            mlflow.pytorch.log_model(model, run_name, conda_env='/mnt/configs/conda.yml')\n",
    "\n",
    "                  \n",
    "    return history, best_preds, best_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-diary",
   "metadata": {},
   "source": [
    "La fonction suivante exploite l'entraîneme,nt sur un fold pour l'étendre sur du k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "boring-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_and_test_preds(mlf_XP, model_type, tokenizer, \n",
    "                           train_df, test_df, single_model=False):\n",
    "    \n",
    "    \n",
    "    mlflow.set_experiment(mlf_XP)\n",
    "    \n",
    "    \n",
    "    oof_preds = []\n",
    "    oof_outputs = []\n",
    "    oof_preds_indices = []\n",
    "    test_preds_list = []\n",
    "    test_outputs_list = []\n",
    "    history_list = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    fold = 0\n",
    "    \n",
    "    x_train = train_df['text']\n",
    "    y_train = train_df['sentiment']\n",
    "\n",
    "    for train_index, val_index in skf.split(x_train, y_train):\n",
    "        print('Fold: {}'.format(fold+1))\n",
    "        \n",
    "        x_tr = x_train.iloc[train_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        x_va = x_train.iloc[val_index]\n",
    "        y_va = y_train.iloc[val_index]\n",
    "        \n",
    "        train = pd.DataFrame(list(zip(x_tr, y_tr)), \n",
    "                             columns=['text', 'sentiment'])\n",
    "        val = pd.DataFrame(list(zip(x_va, y_va)), \n",
    "                           columns=['text', 'sentiment'])\n",
    "\n",
    "        train_ds = create_dataset(train, tokenizer, MAX_LENGTH)\n",
    "        val_ds = create_dataset(val, tokenizer, MAX_LENGTH)\n",
    "        test_ds = create_dataset(test_df, tokenizer, MAX_LENGTH)\n",
    "        \n",
    "\n",
    "        if model_type == 'bert':\n",
    "            model = BERTSentimentClassifier(NUM_CLASSES)\n",
    "            model = model.to(device)\n",
    "        elif model_type == 'distilbert':\n",
    "            model = DistilBertForSequenceClassification(pretrained_model_name=DISTILBERT_MODEL_NAME, \n",
    "                                                        num_classes=NUM_CLASSES)\n",
    "            model = model.to(device)\n",
    "        elif model_type == 'roberta':\n",
    "            model = RobertaSentimentClassifier(n_classes=NUM_CLASSES)\n",
    "            model = model.to(device)\n",
    "        \n",
    "        train_loader = create_dataloader(train_ds, BATCH_SIZE)\n",
    "        val_loader = create_dataloader(val_ds, BATCH_SIZE)\n",
    "        test_loader = create_dataloader(test_ds, BATCH_SIZE)\n",
    "        \n",
    "        training_steps = len(train_loader.dataset) * EPOCHS\n",
    "        warmup_steps = int(0.1 * training_steps)\n",
    "        optimizer = AdamW(model.parameters(), \n",
    "                          lr=LEARNING_RATE, \n",
    "                          weight_decay=WEIGHT_DECAY, \n",
    "                          correct_bias=True)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps=warmup_steps, \n",
    "                                                    num_training_steps=training_steps)\n",
    "        \n",
    "        model_save_name = '{}_fold_{}.bin'.format(model_type, fold)\n",
    "        \n",
    "        history, preds, outputs = train_fold(mlf_XP = mlf_XP, \n",
    "                                             xp_name_iter = model_type + '_Fold' + str(fold+1),\n",
    "                                             epochs=EPOCHS,\n",
    "                                             model=model, \n",
    "                                             device=device, \n",
    "                                             train_dataloader=train_loader, \n",
    "                                             val_dataloader=val_loader,\n",
    "                                             test_dataloader=test_loader,\n",
    "                                             loss_fn=loss_function,\n",
    "                                             optimizer=optimizer,\n",
    "                                             scheduler=scheduler,\n",
    "                                             model_save_name=model_save_name,\n",
    "                                             n_train=len(train),\n",
    "                                             n_val=len(val),\n",
    "                                             single_model=False\n",
    "                                            )\n",
    "        \n",
    "        history_list.append(history)\n",
    "        oof_preds.append(preds)\n",
    "        oof_outputs.append(outputs)\n",
    "        oof_preds_indices.append(val_index)\n",
    "        \n",
    "        test_acc, test_loss, test_actuals, test_preds, test_outputs = eval_model(model, \n",
    "                                                                                device, \n",
    "                                                                                test_loader, \n",
    "                                                                                loss_function, \n",
    "                                                                                len(test_df))\n",
    "        test_preds_list.append(test_preds)\n",
    "        test_outputs_list.append(test_outputs)\n",
    "        \n",
    "        fold += 1\n",
    "\n",
    "    print(str(NFOLDS), 'Fold CV Train Time: ', format_time(time.time() - start_time))\n",
    "\n",
    "    return history_list, test_outputs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-refrigerator",
   "metadata": {},
   "source": [
    "La fonction de perte choisie est la cross entropy.\n",
    "La perte de Cross-entropy croit lorsque la probabilité prédite pour une classe diverge du label réel. Ainsi, uen prédiction de 0,12 alors que le label réel est 1 se traduirait en une forte pénalisation. Un modèle parfait aurait une log loss de 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "excited-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-fancy",
   "metadata": {},
   "source": [
    "Pour la féinition des k fold on efefctue un échantillonnage stratifié afin de conserver la proportion de chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "western-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-selection",
   "metadata": {},
   "source": [
    "### Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-poster",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "On est obligé de recoder les sorties car laisser un label cible négatif génère une erreur `CUDA error: device-side assert triggered`\n",
    "cf [lien](https://discuss.pytorch.org/t/runtimeerror-cuda-error-device-side-assert-triggered/34213/8)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "celtic-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df_train['sentiment'] = le.fit_transform(df_train['sentiment'])\n",
    "df_val['sentiment'] = le.fit_transform(df_val['sentiment'])\n",
    "df_test['sentiment'] = le.fit_transform(df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "persistent-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21979</th>\n",
       "      <td>No allowed a calculator for this exam despite ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21980</th>\n",
       "      <td>Haha same as miine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21981</th>\n",
       "      <td>i`m sorry people are so rude to you, isaac, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21982</th>\n",
       "      <td>why? i enjoy fancy meals on my own smtimes, t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21983</th>\n",
       "      <td>oh yeah - love his choregoraphy. the pants......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21984 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "0                    I`d have responded, if I were going          1\n",
       "1          Sooo SAD I will miss you here in San Diego!!!          0\n",
       "2                              my boss is bullying me...          0\n",
       "3                         what interview! leave me alone          0\n",
       "4       Sons of ****, why couldn`t they put them on t...          0\n",
       "...                                                  ...        ...\n",
       "21979  No allowed a calculator for this exam despite ...          0\n",
       "21980                                 Haha same as miine          1\n",
       "21981    i`m sorry people are so rude to you, isaac, ...          0\n",
       "21982   why? i enjoy fancy meals on my own smtimes, t...          2\n",
       "21983   oh yeah - love his choregoraphy. the pants......          1\n",
       "\n",
       "[21984 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "mighty-founder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21984</th>\n",
       "      <td>_JessicaB_**** yip.....aw gonna miss them on bb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21985</th>\n",
       "      <td>_violence heyyyy babyy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21986</th>\n",
       "      <td>Up at 6am on Sunday... Going to meet my mom fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21987</th>\n",
       "      <td>so the Today show still hasn`t gotten in touch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21988</th>\n",
       "      <td>Just checked email and got a follower withb sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27475</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5496 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "21984    _JessicaB_**** yip.....aw gonna miss them on bb          0\n",
       "21985                             _violence heyyyy babyy          0\n",
       "21986  Up at 6am on Sunday... Going to meet my mom fo...          1\n",
       "21987  so the Today show still hasn`t gotten in touch...          1\n",
       "21988  Just checked email and got a follower withb sa...          1\n",
       "...                                                  ...        ...\n",
       "27475   wish we could come see u on Denver  husband l...          0\n",
       "27476   I`ve wondered about rake to.  The client has ...          0\n",
       "27477   Yay good for both of you. Enjoy the break - y...          2\n",
       "27478                         But it was worth it  ****.          2\n",
       "27479     All this flirting going on - The ATG smiles...          1\n",
       "\n",
       "[5496 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "included-automation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27475</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "0                    I`d have responded, if I were going          1\n",
       "1          Sooo SAD I will miss you here in San Diego!!!          0\n",
       "2                              my boss is bullying me...          0\n",
       "3                         what interview! leave me alone          0\n",
       "4       Sons of ****, why couldn`t they put them on t...          0\n",
       "...                                                  ...        ...\n",
       "27475   wish we could come see u on Denver  husband l...          0\n",
       "27476   I`ve wondered about rake to.  The client has ...          0\n",
       "27477   Yay good for both of you. Enjoy the break - y...          2\n",
       "27478                         But it was worth it  ****.          2\n",
       "27479     All this flirting going on - The ATG smiles...          1\n",
       "\n",
       "[27480 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full = pd.concat([df_train, df_val])\n",
    "df_train_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-petersburg",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-saskatchewan",
   "metadata": {},
   "source": [
    "#### Single Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-processor",
   "metadata": {},
   "source": [
    "Beaucoup d'allers retours ont été faits. Afin d'éviter de staurer la mémoir ede la carte graphique il est nécessire de vider la mémoir cache régulièrement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "appropriate-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "del distilbert_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-sally",
   "metadata": {},
   "source": [
    "On utilise un modèle BERT classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "promotional-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = 'bert-base-cased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-nightlife",
   "metadata": {},
   "source": [
    "On créée un DataLoader adapté au tokenizer de BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "lesbian-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_ds = create_dataset(df_train, bert_tokenizer, MAX_LENGTH)\n",
    "bert_test_ds = create_dataset(df_test, bert_tokenizer, MAX_LENGTH)\n",
    "bert_val_ds = create_dataset(df_val, bert_tokenizer, MAX_LENGTH)\n",
    "\n",
    "bert_train_dataloader = create_dataloader(bert_train_ds, BATCH_SIZE)\n",
    "bert_test_dataloader = create_dataloader(bert_test_ds, BATCH_SIZE)\n",
    "bert_val_dataloader = create_dataloader(bert_val_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "nuclear-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTSentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(BERTSentimentClassifier, self).__init__()\n",
    "        self.model = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=False) #ATTENTION : il faut rajouter return_dict=False ici cf https://huggingface.co/transformers/migration.html\n",
    "        self.drop = nn.Dropout(DROPOUT_PROB)\n",
    "        self.output = nn.Linear(self.model.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        output = self.drop(pooled_output)\n",
    "        \n",
    "        return self.output(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-detail",
   "metadata": {},
   "source": [
    "On charge le modèle BERT. Ce faisant on écrase la dernière couche du modèle qu'on réentraînera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "silver-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BERTSentimentClassifier(NUM_CLASSES)\n",
    "bert_model = bert_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-imperial",
   "metadata": {},
   "source": [
    "On définit le moteur d'optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "attended-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = len(bert_train_dataloader.dataset) * EPOCHS\n",
    "\n",
    "bert_optimizer = AdamW(bert_model.parameters(), \n",
    "                       lr=LEARNING_RATE, \n",
    "                       weight_decay=WEIGHT_DECAY, \n",
    "                       correct_bias=True)\n",
    "\n",
    "warmup_steps = int(0.1 * training_steps)\n",
    "bert_scheduler = get_linear_schedule_with_warmup(bert_optimizer, \n",
    "                                                 num_warmup_steps=warmup_steps, \n",
    "                                                 num_training_steps=training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-consultancy",
   "metadata": {},
   "source": [
    "On commence par l'ajustement d'un modèle BERT sur le jeu de données train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pacific-multimedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9318898132361005  |  Train Accuracy:  0.5406659388646288\n",
      "Val Loss:  0.6341141717031945  |  Val Accuracy:  0.7387190684133915\n",
      "Epoch Train Time:  0:03:58\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5870891877136897  |  Train Accuracy:  0.761735807860262\n",
      "Val Loss:  0.5520704225745312  |  Val Accuracy:  0.7720160116448326\n",
      "Epoch Train Time:  0:03:59\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.4959308845160483  |  Train Accuracy:  0.8064501455604076\n",
      "Val Loss:  0.5590653404766737  |  Val Accuracy:  0.777292576419214\n",
      "Epoch Train Time:  0:04:00\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.4160484819113124  |  Train Accuracy:  0.8476619359534207\n",
      "Val Loss:  0.6347552118822932  |  Val Accuracy:  0.772197962154294\n",
      "Epoch Train Time:  0:03:58\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.3328116309335604  |  Train Accuracy:  0.8863719068413392\n",
      "Val Loss:  0.764754705001102  |  Val Accuracy:  0.7701965065502183\n",
      "Epoch Train Time:  0:04:00\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:19:56\n",
      "\n",
      "\n",
      "[[ 803  180   18]\n",
      " [ 228 1071  131]\n",
      " [  24  223  856]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.761     0.802     0.781      1001\n",
      "     neutral      0.727     0.749     0.738      1430\n",
      "    positive      0.852     0.776     0.812      1103\n",
      "\n",
      "    accuracy                          0.772      3534\n",
      "   macro avg      0.780     0.776     0.777      3534\n",
      "weighted avg      0.775     0.772     0.773      3534\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/mnt/rapport/_build/jupyter_execute/notebooks/nn_62_1.png"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_single_model_items = train_fold(mlf_XP='BERT', \n",
    "                                     xp_name_iter='BERT',\n",
    "                                     epochs=EPOCHS, \n",
    "                                     model=bert_model, \n",
    "                                     device=device, \n",
    "                                     train_dataloader=bert_train_dataloader, \n",
    "                                     val_dataloader=bert_val_dataloader,\n",
    "                                     test_dataloader=bert_test_dataloader,\n",
    "                                     loss_fn=loss_function,\n",
    "                                     optimizer=bert_optimizer,\n",
    "                                     scheduler=bert_scheduler,\n",
    "                                     model_save_name='bert_best_model.bin',\n",
    "                                     n_train=len(df_train),\n",
    "                                     n_val=len(df_val),\n",
    "                                     single_model=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-privilege",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Le modèle BERT arrive à un f& macro de **77,7%** sur le jeu de test et se classe directement en tête des modèles\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "every-explorer",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modèle  f1_macro_test\n",
       "0   BERT          0.777"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = pd.DataFrame([['BERT', 0.777]], columns=['modèle', 'f1_macro_test'])\n",
    "\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aware-scotland",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "res_fin=res_fin2.append(item).sort_values(by='f1_macro_test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "constitutional-inflation",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>f1_macro_val</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roBERTa_xgb_opti_</td>\n",
       "      <td>0.759147</td>\n",
       "      <td>0.759953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roBERTa_Blob_Vader_RF_opti_</td>\n",
       "      <td>0.756699</td>\n",
       "      <td>0.750216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roBERTa_RF_opti_</td>\n",
       "      <td>0.746630</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfIdf_LR_opti_modif_seuil</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_TfIdf_RF_prepro_</td>\n",
       "      <td>0.707919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base_TfIdf_RF_prepro_opti_</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roBERTa_RF_</td>\n",
       "      <td>0.705912</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TfIdf_LR_opti_</td>\n",
       "      <td>0.699877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TfIdf_LR_prepro_opti_</td>\n",
       "      <td>0.698565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base_TfIdf_RF_</td>\n",
       "      <td>0.669789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        modèle  f1_macro_val  f1_macro_test\n",
       "0                         BERT           NaN       0.777000\n",
       "0            roBERTa_xgb_opti_      0.759147       0.759953\n",
       "1  roBERTa_Blob_Vader_RF_opti_      0.756699       0.750216\n",
       "2             roBERTa_RF_opti_      0.746630            NaN\n",
       "3    TfIdf_LR_opti_modif_seuil      0.709477            NaN\n",
       "4        base_TfIdf_RF_prepro_      0.707919            NaN\n",
       "5   base_TfIdf_RF_prepro_opti_      0.706432            NaN\n",
       "6                  roBERTa_RF_      0.705912            NaN\n",
       "7               TfIdf_LR_opti_      0.699877            NaN\n",
       "8        TfIdf_LR_prepro_opti_      0.698565            NaN\n",
       "9               base_TfIdf_RF_      0.669789            NaN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-omega",
   "metadata": {},
   "source": [
    "### DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-temperature",
   "metadata": {},
   "source": [
    "On reprend ici la même logique que pour BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-hayes",
   "metadata": {},
   "source": [
    "#### Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "gothic-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTILBERT_MODEL_NAME = 'distilbert-base-uncased'\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(DISTILBERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "trained-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_train_ds = create_dataset(df_train, distilbert_tokenizer, MAX_LENGTH)\n",
    "distilbert_test_ds = create_dataset(df_test, distilbert_tokenizer, MAX_LENGTH)\n",
    "distilbert_val_ds = create_dataset(df_val, distilbert_tokenizer, MAX_LENGTH)\n",
    "\n",
    "distilbert_train_dataloader = create_dataloader(distilbert_train_ds, BATCH_SIZE)\n",
    "distilbert_test_dataloader = create_dataloader(distilbert_test_ds, BATCH_SIZE)\n",
    "distilbert_val_dataloader = create_dataloader(distilbert_val_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "collaborative-peace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TweetDataset at 0x7f4961ff3670>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "naval-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertForSequenceClassification(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_model_name, num_classes):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(pretrained_model_name, num_labels=num_classes)\n",
    "\n",
    "        self.distilbert = AutoModel.from_pretrained(pretrained_model_name, config=config)\n",
    "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
    "        self.classifier = nn.Linear(config.dim, num_classes)\n",
    "        self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, head_mask=None):\n",
    "\n",
    "        assert attention_mask is not None, \"No Attention Mask\"\n",
    "        distilbert_output = self.distilbert(input_ids=input_ids,\n",
    "                                            attention_mask=attention_mask,\n",
    "                                            head_mask=head_mask)\n",
    "\n",
    "        hidden_state = distilbert_output[0]  \n",
    "        pooled_output = hidden_state[:, 0] \n",
    "        pooled_output = self.pre_classifier(pooled_output)  \n",
    "        pooled_output = nn.ReLU()(pooled_output)  \n",
    "        pooled_output = self.dropout(pooled_output)  \n",
    "        logits = self.classifier(pooled_output)  \n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "pretty-basin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d5250cb979411f8e91172ccca10eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762cc910ee2646b5ace87b1512eb5b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "distilbert_model = DistilBertForSequenceClassification(pretrained_model_name=DISTILBERT_MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "distilbert_model = distilbert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "everyday-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = len(distilbert_train_dataloader.dataset) * EPOCHS\n",
    "\n",
    "distilbert_optimizer = AdamW(distilbert_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, correct_bias=True)\n",
    "distilbert_scheduler = get_linear_schedule_with_warmup(distilbert_optimizer, num_warmup_steps=int(0.1 * training_steps), num_training_steps=training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "insured-cross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "married-saudi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9396719512417153  |  Train Accuracy:  0.5367540029112081\n",
      "Val Loss:  0.6267227158816748  |  Val Accuracy:  0.7505458515283843\n",
      "Epoch Train Time:  0:02:09\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5887683325784696  |  Train Accuracy:  0.7622361717612809\n",
      "Val Loss:  0.5463424418987923  |  Val Accuracy:  0.7736535662299855\n",
      "Epoch Train Time:  0:02:07\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.510728445874725  |  Train Accuracy:  0.7969887190684134\n",
      "Val Loss:  0.5309577705988358  |  Val Accuracy:  0.7862081513828238\n",
      "Epoch Train Time:  0:02:07\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.44334969244723843  |  Train Accuracy:  0.8310134643377002\n",
      "Val Loss:  0.578479872539986  |  Val Accuracy:  0.7860262008733624\n",
      "Epoch Train Time:  0:02:07\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.37767219023570264  |  Train Accuracy:  0.8633096797671034\n",
      "Val Loss:  0.6317601318167912  |  Val Accuracy:  0.7809315866084425\n",
      "Epoch Train Time:  0:02:06\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:10:37\n",
      "\n",
      "\n",
      "[[ 790  189   22]\n",
      " [ 206 1087  137]\n",
      " [  26  187  890]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.773     0.789     0.781      1001\n",
      "     neutral      0.743     0.760     0.751      1430\n",
      "    positive      0.848     0.807     0.827      1103\n",
      "\n",
      "    accuracy                          0.783      3534\n",
      "   macro avg      0.788     0.785     0.787      3534\n",
      "weighted avg      0.784     0.783     0.783      3534\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/mnt/rapport/_build/jupyter_execute/notebooks/nn_77_1.png"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distilbert_history, distilbert_preds, distilbert_outputs = train_fold(mlf_XP='BERT', \n",
    "                                                                       xp_name_iter='DistilBERT',\n",
    "                                                                       epochs=EPOCHS,\n",
    "                                                                       model=distilbert_model,\n",
    "                                                                       device=device, \n",
    "                                                                       train_dataloader=distilbert_train_dataloader, \n",
    "                                                                       val_dataloader=distilbert_val_dataloader,\n",
    "                                                                       test_dataloader=distilbert_test_dataloader,\n",
    "                                                                       loss_fn=loss_function,\n",
    "                                                                       optimizer=distilbert_optimizer,\n",
    "                                                                       scheduler=distilbert_scheduler,\n",
    "                                                                       model_save_name='distilbest_best_model.bin',\n",
    "                                                                       n_train=len(df_train),\n",
    "                                                                       n_val=len(df_val),\n",
    "                                                                       single_model=True\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-operations",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "DistilBERT tient toutes ses promesses, il présente un f1 macro de **78,7%** pour un temps 2 fois moindre\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "plastic-outline",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBERT</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       modèle  f1_macro_test\n",
       "0  DistilBERT          0.787"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = pd.DataFrame([['DistilBERT', 0.787]], columns=['modèle', 'f1_macro_test'])\n",
    "\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "joined-catalog",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "res_fin=res_fin.append(item).sort_values(by='f1_macro_test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "major-royal",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>f1_macro_val</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roBERTa_xgb_opti_</td>\n",
       "      <td>0.759147</td>\n",
       "      <td>0.759953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roBERTa_Blob_Vader_RF_opti_</td>\n",
       "      <td>0.756699</td>\n",
       "      <td>0.750216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roBERTa_RF_opti_</td>\n",
       "      <td>0.746630</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfIdf_LR_opti_modif_seuil</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_TfIdf_RF_prepro_</td>\n",
       "      <td>0.707919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base_TfIdf_RF_prepro_opti_</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roBERTa_RF_</td>\n",
       "      <td>0.705912</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TfIdf_LR_opti_</td>\n",
       "      <td>0.699877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TfIdf_LR_prepro_opti_</td>\n",
       "      <td>0.698565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base_TfIdf_RF_</td>\n",
       "      <td>0.669789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        modèle  f1_macro_val  f1_macro_test\n",
       "0                   DistilBERT           NaN       0.787000\n",
       "0                         BERT           NaN       0.777000\n",
       "0            roBERTa_xgb_opti_      0.759147       0.759953\n",
       "1  roBERTa_Blob_Vader_RF_opti_      0.756699       0.750216\n",
       "2             roBERTa_RF_opti_      0.746630            NaN\n",
       "3    TfIdf_LR_opti_modif_seuil      0.709477            NaN\n",
       "4        base_TfIdf_RF_prepro_      0.707919            NaN\n",
       "5   base_TfIdf_RF_prepro_opti_      0.706432            NaN\n",
       "6                  roBERTa_RF_      0.705912            NaN\n",
       "7               TfIdf_LR_opti_      0.699877            NaN\n",
       "8        TfIdf_LR_prepro_opti_      0.698565            NaN\n",
       "9               base_TfIdf_RF_      0.669789            NaN"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-brisbane",
   "metadata": {},
   "source": [
    "#### 10-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-prize",
   "metadata": {},
   "source": [
    "Le temps d'ajustement étant relativement court, on peut se permettre de faire un modèle ensembliste à partir d'un ajustement 10-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "external-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.941926259658315  |  Train Accuracy:  0.522400129387029\n",
      "Val Loss:  0.6203636002055434  |  Val Accuracy:  0.7558224163027657\n",
      "Epoch Train Time:  0:02:25\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.580964529094073  |  Train Accuracy:  0.7636665049328805\n",
      "Val Loss:  0.5477447283649167  |  Val Accuracy:  0.7776564774381368\n",
      "Epoch Train Time:  0:02:18\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5048014043286964  |  Train Accuracy:  0.7982371017305515\n",
      "Val Loss:  0.545227823259179  |  Val Accuracy:  0.7900291120815138\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.44333723517084184  |  Train Accuracy:  0.8298964903768398\n",
      "Val Loss:  0.5853824304893266  |  Val Accuracy:  0.7863901018922853\n",
      "Epoch Train Time:  0:02:15\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.3777913040834519  |  Train Accuracy:  0.8617176128093159\n",
      "Val Loss:  0.6538275292273178  |  Val Accuracy:  0.784570596797671\n",
      "Epoch Train Time:  0:02:15\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:30\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9205003487377549  |  Train Accuracy:  0.5397865114022319\n",
      "Val Loss:  0.6180462270628574  |  Val Accuracy:  0.7456331877729258\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.579977193917178  |  Train Accuracy:  0.7666181465308103\n",
      "Val Loss:  0.5480122222716726  |  Val Accuracy:  0.7762008733624454\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5064557375046599  |  Train Accuracy:  0.7976306000323468\n",
      "Val Loss:  0.5441750175384588  |  Val Accuracy:  0.7878457059679768\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.44550948646425587  |  Train Accuracy:  0.8284813197476953\n",
      "Val Loss:  0.5777701539702194  |  Val Accuracy:  0.7918486171761281\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.3740355369091554  |  Train Accuracy:  0.8634562510108361\n",
      "Val Loss:  0.6463065561188688  |  Val Accuracy:  0.787117903930131\n",
      "Epoch Train Time:  0:02:15\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:22\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9184577913827143  |  Train Accuracy:  0.5359453339802684\n",
      "Val Loss:  0.6066395441113517  |  Val Accuracy:  0.7554585152838428\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5813285425054765  |  Train Accuracy:  0.7635047711466926\n",
      "Val Loss:  0.5406240603431712  |  Val Accuracy:  0.7852983988355168\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5067589409977082  |  Train Accuracy:  0.7990862041080382\n",
      "Val Loss:  0.5343165016451548  |  Val Accuracy:  0.7914847161572053\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.4455857805083632  |  Train Accuracy:  0.8299773572699337\n",
      "Val Loss:  0.5721239838315997  |  Val Accuracy:  0.7918486171761281\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.3778618352793707  |  Train Accuracy:  0.8634562510108361\n",
      "Val Loss:  0.6522320938015054  |  Val Accuracy:  0.7885735080058224\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:22\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9359287480988755  |  Train Accuracy:  0.5133834708070516\n",
      "Val Loss:  0.6244141412682311  |  Val Accuracy:  0.745269286754003\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5799717282416132  |  Train Accuracy:  0.7639091056121624\n",
      "Val Loss:  0.5602689084358686  |  Val Accuracy:  0.774745269286754\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.505196814004809  |  Train Accuracy:  0.7991670710011322\n",
      "Val Loss:  0.5649052176971076  |  Val Accuracy:  0.7791120815138283\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.4425473887989006  |  Train Accuracy:  0.8301795245026686\n",
      "Val Loss:  0.6196258552805629  |  Val Accuracy:  0.7834788937409025\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.37172359224399226  |  Train Accuracy:  0.864022319262494\n",
      "Val Loss:  0.7073620971465526  |  Val Accuracy:  0.774745269286754\n",
      "Epoch Train Time:  0:02:15\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:22\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9415115041689608  |  Train Accuracy:  0.5170629144428271\n",
      "Val Loss:  0.6350645698433699  |  Val Accuracy:  0.7434497816593887\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5827579239014666  |  Train Accuracy:  0.7607957302280446\n",
      "Val Loss:  0.5471963639869246  |  Val Accuracy:  0.7867540029112081\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5057246983581419  |  Train Accuracy:  0.7993692382338671\n",
      "Val Loss:  0.5351174239848935  |  Val Accuracy:  0.7998544395924309\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.4470801455044654  |  Train Accuracy:  0.8266213812065341\n",
      "Val Loss:  0.5497014267413423  |  Val Accuracy:  0.7991266375545851\n",
      "Epoch Train Time:  0:02:15\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.37871522154962645  |  Train Accuracy:  0.86139414523694\n",
      "Val Loss:  0.6404869829759349  |  Val Accuracy:  0.7962154294032023\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:21\n",
      "\n",
      "\n",
      "Fold: 6\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9295003596129423  |  Train Accuracy:  0.5452045932395277\n",
      "Val Loss:  0.6083728503002677  |  Val Accuracy:  0.75509461426492\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5811521254605186  |  Train Accuracy:  0.7621300339640951\n",
      "Val Loss:  0.5365904703909574  |  Val Accuracy:  0.784570596797671\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5050301146952563  |  Train Accuracy:  0.7982775351770985\n",
      "Val Loss:  0.5421336143342561  |  Val Accuracy:  0.7867540029112081\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.4430553875285241  |  Train Accuracy:  0.8300582241630277\n",
      "Val Loss:  0.5596038565732712  |  Val Accuracy:  0.7958515283842795\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.3792365301860663  |  Train Accuracy:  0.8621623807213327\n",
      "Val Loss:  0.634867753075479  |  Val Accuracy:  0.7893013100436681\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:22\n",
      "\n",
      "\n",
      "Fold: 7\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9052738494313242  |  Train Accuracy:  0.5478732007116287\n",
      "Val Loss:  0.6165331214839636  |  Val Accuracy:  0.7536390101892285\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5792397190401039  |  Train Accuracy:  0.7655264434740418\n",
      "Val Loss:  0.5519887229730917  |  Val Accuracy:  0.7812954876273653\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.503106549497872  |  Train Accuracy:  0.7999757399320718\n",
      "Val Loss:  0.5589800931859848  |  Val Accuracy:  0.7842066957787481\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.4417677537561003  |  Train Accuracy:  0.8299773572699337\n",
      "Val Loss:  0.5645578062205121  |  Val Accuracy:  0.7947598253275109\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.3713598938401003  |  Train Accuracy:  0.8643457868348698\n",
      "Val Loss:  0.6417522168783254  |  Val Accuracy:  0.7903930131004366\n",
      "Epoch Train Time:  0:02:15\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:21\n",
      "\n",
      "\n",
      "Fold: 8\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9064137189423745  |  Train Accuracy:  0.56420831311661\n",
      "Val Loss:  0.60685450930235  |  Val Accuracy:  0.75254730713246\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5819097766255114  |  Train Accuracy:  0.7641517062914442\n",
      "Val Loss:  0.531711004327896  |  Val Accuracy:  0.7812954876273653\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5045987542087326  |  Train Accuracy:  0.7986818696425684\n",
      "Val Loss:  0.5272369070281816  |  Val Accuracy:  0.7918486171761281\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.44432073352041557  |  Train Accuracy:  0.8300986576095747\n",
      "Val Loss:  0.5473811943084002  |  Val Accuracy:  0.7940320232896652\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.3745883988724952  |  Train Accuracy:  0.8643457868348698\n",
      "Val Loss:  0.6393082001094901  |  Val Accuracy:  0.7831149927219796\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:22\n",
      "\n",
      "\n",
      "Fold: 9\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9189361214522094  |  Train Accuracy:  0.5487223030891153\n",
      "Val Loss:  0.6407536754254685  |  Val Accuracy:  0.7245269286754003\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5772791211655963  |  Train Accuracy:  0.7660520782791526\n",
      "Val Loss:  0.582675036476102  |  Val Accuracy:  0.7612809315866085\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5016376986608083  |  Train Accuracy:  0.8010674429888404\n",
      "Val Loss:  0.6005498271782038  |  Val Accuracy:  0.7711062590975255\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.43999696849697156  |  Train Accuracy:  0.8320394630438298\n",
      "Val Loss:  0.6376301472963288  |  Val Accuracy:  0.7641921397379913\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.3717861590728665  |  Train Accuracy:  0.8649522885330746\n",
      "Val Loss:  0.7558341780894025  |  Val Accuracy:  0.7634643377001455\n",
      "Epoch Train Time:  0:02:15\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:20\n",
      "\n",
      "\n",
      "Fold: 10\n",
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9245070222124245  |  Train Accuracy:  0.5524826136179848\n",
      "Val Loss:  0.6224677699596383  |  Val Accuracy:  0.74745269286754\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5746363384160003  |  Train Accuracy:  0.7660520782791526\n",
      "Val Loss:  0.545842379764762  |  Val Accuracy:  0.777292576419214\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5028234107364427  |  Train Accuracy:  0.8005013747371826\n",
      "Val Loss:  0.5520749990503455  |  Val Accuracy:  0.784570596797671\n",
      "Epoch Train Time:  0:02:17\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.44011698519861636  |  Train Accuracy:  0.8330502992075044\n",
      "Val Loss:  0.5861991313394419  |  Val Accuracy:  0.7885735080058224\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.3778763751934293  |  Train Accuracy:  0.8624454148471615\n",
      "Val Loss:  0.6675134595093686  |  Val Accuracy:  0.7816593886462883\n",
      "Epoch Train Time:  0:02:16\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:11:22\n",
      "\n",
      "\n",
      "10 Fold CV Train Time:  1:54:57\n"
     ]
    }
   ],
   "source": [
    "distilbert_history, distilbert_test_outputs = get_oof_and_test_preds(mlf_XP='DistilBERT_10Fold',\n",
    "                                                                     model_type='distilbert', \n",
    "                                                                     tokenizer=distilbert_tokenizer, \n",
    "                                                                     train_df=df_train_full, \n",
    "                                                                     test_df=df_test,\n",
    "                                                                     single_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "imported-district",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 739  235   27]\n",
      " [ 148 1123  159]\n",
      " [  20  165  918]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.815     0.738     0.775      1001\n",
      "     neutral      0.737     0.785     0.761      1430\n",
      "    positive      0.832     0.832     0.832      1103\n",
      "\n",
      "    accuracy                          0.787      3534\n",
      "   macro avg      0.795     0.785     0.789      3534\n",
      "weighted avg      0.789     0.787     0.787      3534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_ensemble_performance(distilbert_test_outputs, df_test['sentiment'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-bosnia",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "DistilBERT 10 fold présente un f1 macro à peine amélioré **78,9%** pour un temps **11,5** fois plus important !\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "accessory-wiring",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBERT_10-fold</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               modèle  f1_macro_test\n",
       "0  DistilBERT_10-fold          0.789"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = pd.DataFrame([['DistilBERT_10-fold', 0.789]], columns=['modèle', 'f1_macro_test'])\n",
    "\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "republican-rebecca",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "res_fin=res_fin.append(item).sort_values(by='f1_macro_test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "subjective-breakdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>f1_macro_val</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBERT_10-fold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roBERTa_xgb_opti_</td>\n",
       "      <td>0.759147</td>\n",
       "      <td>0.759953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roBERTa_Blob_Vader_RF_opti_</td>\n",
       "      <td>0.756699</td>\n",
       "      <td>0.750216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roBERTa_RF_opti_</td>\n",
       "      <td>0.746630</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfIdf_LR_opti_modif_seuil</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_TfIdf_RF_prepro_</td>\n",
       "      <td>0.707919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base_TfIdf_RF_prepro_opti_</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roBERTa_RF_</td>\n",
       "      <td>0.705912</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TfIdf_LR_opti_</td>\n",
       "      <td>0.699877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TfIdf_LR_prepro_opti_</td>\n",
       "      <td>0.698565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base_TfIdf_RF_</td>\n",
       "      <td>0.669789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        modèle  f1_macro_val  f1_macro_test\n",
       "0           DistilBERT_10-fold           NaN       0.789000\n",
       "0                   DistilBERT           NaN       0.787000\n",
       "0                         BERT           NaN       0.777000\n",
       "0            roBERTa_xgb_opti_      0.759147       0.759953\n",
       "1  roBERTa_Blob_Vader_RF_opti_      0.756699       0.750216\n",
       "2             roBERTa_RF_opti_      0.746630            NaN\n",
       "3    TfIdf_LR_opti_modif_seuil      0.709477            NaN\n",
       "4        base_TfIdf_RF_prepro_      0.707919            NaN\n",
       "5   base_TfIdf_RF_prepro_opti_      0.706432            NaN\n",
       "6                  roBERTa_RF_      0.705912            NaN\n",
       "7               TfIdf_LR_opti_      0.699877            NaN\n",
       "8        TfIdf_LR_prepro_opti_      0.698565            NaN\n",
       "9               base_TfIdf_RF_      0.669789            NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-omega",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-partition",
   "metadata": {},
   "source": [
    "Le dernier modèle testé est RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-garlic",
   "metadata": {},
   "source": [
    "#### Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "provincial-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "del bert_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dedicated-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTA_MODEL_NAME = 'roberta-base'\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "vietnamese-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_train_ds = create_dataset(df_train, roberta_tokenizer, MAX_LENGTH)\n",
    "roberta_test_ds = create_dataset(df_test, roberta_tokenizer, MAX_LENGTH)\n",
    "roberta_val_ds = create_dataset(df_val, roberta_tokenizer, MAX_LENGTH)\n",
    "\n",
    "roberta_train_dataloader = create_dataloader(roberta_train_ds, BATCH_SIZE)\n",
    "roberta_test_dataloader = create_dataloader(roberta_test_ds, BATCH_SIZE)\n",
    "roberta_val_dataloader = create_dataloader(roberta_val_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "recent-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaSentimentClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super(RobertaSentimentClassifier, self).__init__()\n",
    "        self.model = RobertaModel.from_pretrained(ROBERTA_MODEL_NAME, return_dict=False) #ATTENTION : il faut rajouter return_dict=False ici cf https://huggingface.co/transformers/migration.html\n",
    "        self.drop = nn.Dropout(DROPOUT_PROB)\n",
    "        self.output = nn.Linear(self.model.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        output = self.drop(pooled_output)\n",
    "        \n",
    "        return self.output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "distinguished-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_model = RobertaSentimentClassifier(n_classes=NUM_CLASSES)\n",
    "roberta_model = roberta_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "brilliant-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = len(roberta_train_dataloader.dataset) * EPOCHS\n",
    "\n",
    "roberta_optimizer = AdamW(roberta_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, correct_bias=True)\n",
    "roberta_scheduler = get_linear_schedule_with_warmup(roberta_optimizer, num_warmup_steps=int(0.1 * training_steps), num_training_steps=training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "behind-appendix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.9043195859205081  |  Train Accuracy:  0.5254275836972343\n",
      "Val Loss:  0.5874736773846454  |  Val Accuracy:  0.7574599708879185\n",
      "Epoch Train Time:  0:09:34\n",
      "\n",
      "\n",
      "Epoch  2 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.5546561090012652  |  Train Accuracy:  0.7763373362445415\n",
      "Val Loss:  0.5240757602678482  |  Val Accuracy:  0.7867540029112081\n",
      "Epoch Train Time:  0:09:30\n",
      "\n",
      "\n",
      "Epoch  3 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.48944837608126573  |  Train Accuracy:  0.8069050218340611\n",
      "Val Loss:  0.5171312416232255  |  Val Accuracy:  0.787117903930131\n",
      "Epoch Train Time:  0:09:31\n",
      "\n",
      "\n",
      "Epoch  4 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.43777817099733385  |  Train Accuracy:  0.8314683406113537\n",
      "Val Loss:  0.5419738723484929  |  Val Accuracy:  0.7860262008733624\n",
      "Epoch Train Time:  0:09:28\n",
      "\n",
      "\n",
      "Epoch  5 / 5\n",
      "--------------------------------------------------\n",
      "Train Loss:  0.38452990322605624  |  Train Accuracy:  0.8561681222707423\n",
      "Val Loss:  0.6697040315565848  |  Val Accuracy:  0.7749272197962155\n",
      "Epoch Train Time:  0:09:30\n",
      "\n",
      "\n",
      "Finished Training.\n",
      "Fold Train Time:  0:47:33\n",
      "\n",
      "\n",
      "[[ 771  193   37]\n",
      " [ 159 1066  205]\n",
      " [  19  128  956]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.812     0.770     0.791      1001\n",
      "     neutral      0.769     0.745     0.757      1430\n",
      "    positive      0.798     0.867     0.831      1103\n",
      "\n",
      "    accuracy                          0.790      3534\n",
      "   macro avg      0.793     0.794     0.793      3534\n",
      "weighted avg      0.790     0.790     0.790      3534\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/mnt/rapport/_build/jupyter_execute/notebooks/nn_99_1.png"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roberta_single_model_items = train_fold(  \n",
    "                                          mlf_XP='RoBERTa', \n",
    "                                          xp_name_iter='RoBERTa',\n",
    "                                          epochs=EPOCHS,\n",
    "                                          model=roberta_model,\n",
    "                                          device=device, \n",
    "                                          train_dataloader=roberta_train_dataloader, \n",
    "                                          val_dataloader=roberta_val_dataloader,\n",
    "                                          test_dataloader=roberta_test_dataloader,\n",
    "                                          loss_fn=loss_function,\n",
    "                                          optimizer=roberta_optimizer,\n",
    "                                          scheduler=roberta_scheduler,\n",
    "                                          model_save_name='roberta_best_model.bin',\n",
    "                                          n_train=len(df_train),\n",
    "                                          n_val=len(df_val),\n",
    "                                          single_model=True\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-qatar",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "RoBERTa est très lent à ajuster (47 min vs 10 min pour DistilBERT). Par contre il présente un f1 macro amélioré à **79,3%**\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "narrow-double",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RoBERTa</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    modèle  f1_macro_test\n",
       "0  RoBERTa          0.793"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = pd.DataFrame([['RoBERTa', 0.793]], columns=['modèle', 'f1_macro_test'])\n",
    "\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "pharmaceutical-publicity",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "res_fin=res_fin.append(item).sort_values(by='f1_macro_test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "taken-greenhouse",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modèle</th>\n",
       "      <th>f1_macro_val</th>\n",
       "      <th>f1_macro_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RoBERTa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBERT_10-fold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roBERTa_xgb_opti_</td>\n",
       "      <td>0.759147</td>\n",
       "      <td>0.759953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roBERTa_Blob_Vader_RF_opti_</td>\n",
       "      <td>0.756699</td>\n",
       "      <td>0.750216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roBERTa_RF_opti_</td>\n",
       "      <td>0.746630</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfIdf_LR_opti_modif_seuil</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_TfIdf_RF_prepro_</td>\n",
       "      <td>0.707919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base_TfIdf_RF_prepro_opti_</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roBERTa_RF_</td>\n",
       "      <td>0.705912</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TfIdf_LR_opti_</td>\n",
       "      <td>0.699877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TfIdf_LR_prepro_opti_</td>\n",
       "      <td>0.698565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base_TfIdf_RF_</td>\n",
       "      <td>0.669789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        modèle  f1_macro_val  f1_macro_test\n",
       "0                      RoBERTa           NaN       0.793000\n",
       "0           DistilBERT_10-fold           NaN       0.789000\n",
       "0                   DistilBERT           NaN       0.787000\n",
       "0                         BERT           NaN       0.777000\n",
       "0            roBERTa_xgb_opti_      0.759147       0.759953\n",
       "1  roBERTa_Blob_Vader_RF_opti_      0.756699       0.750216\n",
       "2             roBERTa_RF_opti_      0.746630            NaN\n",
       "3    TfIdf_LR_opti_modif_seuil      0.709477            NaN\n",
       "4        base_TfIdf_RF_prepro_      0.707919            NaN\n",
       "5   base_TfIdf_RF_prepro_opti_      0.706432            NaN\n",
       "6                  roBERTa_RF_      0.705912            NaN\n",
       "7               TfIdf_LR_opti_      0.699877            NaN\n",
       "8        TfIdf_LR_prepro_opti_      0.698565            NaN\n",
       "9               base_TfIdf_RF_      0.669789            NaN"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "electronic-centre",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "res_fin.to_parquet('/mnt/data/processed/res_fin3.gzip',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-museum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}