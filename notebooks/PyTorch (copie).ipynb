{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "automated-richards",
   "metadata": {},
   "source": [
    "# test pyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-monday",
   "metadata": {},
   "source": [
    "source : **Twitter-roBERTa-base for Sentiment Analysis**\n",
    "\n",
    "sur [Hugging Face ](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tight-antarctica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hybrid-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "catholic-ability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.5.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.56.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "radical-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "medieval-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "\n",
    "\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adopted-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "#task='sentiment'\n",
    "#MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "joint-rogers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "wrapped-litigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardiffnlp/twitter-roberta-base-sentiment\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import pipeline\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "print(MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained('../pretrained_models/'+MODEL)\n",
    "tokenizer.save_pretrained('../pretrained_models/'+MODEL)\n",
    "config.save_pretrained('../pretrained_models/'+MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "russian-effect",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-adfbd53041ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msentence\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m'Hello World!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-large-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-large-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BertTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "sentence  = 'Hello World!'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model     = BertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "inputs    = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "model     = model.to(device)\n",
    "outputs   = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caring-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForSequenceClassification.from_pretrained(MODEL) \n",
    "#model.save_pretrained(MODEL)\n",
    "#tokenizer.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cardiac-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "#config = AutoConfig.from_pretrained(MODEL)\n",
    "#config.save_pretrained('YOURPATH')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "concrete-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.save_pretrained('YOURPATH')\n",
    "#config.save_pretrained('YOURPATH')\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained('YOURPATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "french-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "severe-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "velvet-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=0, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "hourly-lawsuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.007609867490828037},\n",
       "  {'label': 'LABEL_1', 'score': 0.1458120346069336},\n",
       "  {'label': 'LABEL_2', 'score': 0.8465781211853027}]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "\n",
    "nlp(text, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fiscal-dealer",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input, output and indices must be on the current device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-5efb1d193123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    809\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input, output and indices must be on the current device"
     ]
    }
   ],
   "source": [
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "boring-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.8466\n",
      "2) neutral 0.1458\n",
      "3) negative 0.0076\n"
     ]
    }
   ],
   "source": [
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-insurance",
   "metadata": {},
   "source": [
    "# ==== RECUP ML ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bearing-front",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.6.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.56.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "finnish-adolescent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 17.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.8/dist-packages (from textblob) (3.6.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (4.56.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (2020.11.13)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accessible-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.7.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (51.1.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.56.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.0.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (1.1.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "effective-threat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Temps et fichiers\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "#Manipulation de données\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Text\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import re\n",
    "import spacy \n",
    "\n",
    "\n",
    "#Modélisation\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import RandomizedSearchCV# the keys can be accessed with final_pipeline.get_params().keys()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "#Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "#Tracking d'expérience\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-forum",
   "metadata": {},
   "source": [
    "### Utilisation du code du projet packagé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bridal-found",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Cette cellule permet d'appeler la version packagée du projet et d'en assurer le reload avant appel des fonctions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "forbidden-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsa_sentiment.scripts.make_dataset import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "humanitarian-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dsa_sentiment.scripts.evaluate import eval_metrics\n",
    "from dsa_sentiment.scripts.evaluate import eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "miniature-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsa_sentiment.scripts.make_dataset import Preprocess_StrLower, Preprocess_transform_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-ending",
   "metadata": {},
   "source": [
    "### Configuration de l'experiment MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "velvet-college",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/experiments'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "brown-locking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'DSA_sentiment_GPU' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "exp_name=\"DSA_sentiment_GPU\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-attribute",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "suburban-crowd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/raw/sample_submission.csv',\n",
       " '../data/raw/test.csv',\n",
       " '../data/raw/train.csv']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = os.path.join('..', 'data', 'raw')\n",
    "all_raw_files = [os.path.join(data_folder, fname)\n",
    "                    for fname in os.listdir(data_folder)]\n",
    "all_raw_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "loose-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-burke",
   "metadata": {},
   "source": [
    "Il n'est pas possible de faire de l'imputation comme avec des champs numérique. Il convient donc de supprimer les entrées vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "laughing-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = load_data(all_raw_files[2], split=True, test_size=0.3, random_state=random_state, dropNA=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "twenty-marker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text  \n",
       "0  I`d have responded, if I were going  \n",
       "1                             Sooo SAD  \n",
       "2                          bullying me  \n",
       "3                       leave me alone  \n",
       "4                        Sons of ****,  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "protective-norway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment\n",
       "0   neutral\n",
       "1  negative\n",
       "2  negative\n",
       "3  negative\n",
       "4  negative"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "japanese-chrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27480"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0] + X_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "together-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_data(all_raw_files[1], split=False, random_state=random_state, dropNA=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "numeric-guatemala",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...\n",
       "3  01082688c6                                        happy bday!\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "polyphonic-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3534 entries, 0 to 3533\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   textID  3534 non-null   object\n",
      " 1   text    3534 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 55.3+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "foster-warrior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment\n",
       "0   neutral\n",
       "1  positive\n",
       "2  negative\n",
       "3  positive\n",
       "4  positive"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "instructional-shore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                i`d have responded, if i were going   \n",
       "1  549e992a42      sooo sad i will miss you here in san diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text  \n",
       "0  I`d have responded, if I were going  \n",
       "1                             Sooo SAD  \n",
       "2                          bullying me  \n",
       "3                       leave me alone  \n",
       "4                        Sons of ****,  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = Preprocess_StrLower(X_train, columns_to_process=['text'])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "environmental-bride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0          0\n",
       "1         -1\n",
       "2         -1\n",
       "3         -1\n",
       "4         -1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = Preprocess_transform_target(y_train, columns_to_process=['sentiment'])\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "tested-preliminary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19236</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19237</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19238</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19239</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19240</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "19236          0\n",
       "19237         -1\n",
       "19238          1\n",
       "19239         -1\n",
       "19240          1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = Preprocess_transform_target(y_val, ['sentiment'])\n",
    "y_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "informed-farming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day  http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>shanghai is also really exciting (precisely -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>recession hit veronique branquinho, she has to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - i like it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text\n",
       "0  f87dea47db  last session of the day  http://twitpic.com/67ezh\n",
       "1  96d74cb729   shanghai is also really exciting (precisely -...\n",
       "2  eee518ae67  recession hit veronique branquinho, she has to...\n",
       "3  01082688c6                                        happy bday!\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - i like it!!"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = Preprocess_StrLower(X_test, columns_to_process=['text'])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "encouraging-finland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0          0\n",
       "1          1\n",
       "2         -1\n",
       "3          1\n",
       "4          1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = Preprocess_transform_target(y_test, ['sentiment'])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-offer",
   "metadata": {},
   "source": [
    "# === ESSAI HUGGING FACE ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "about-trader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                i`d have responded, if i were going   \n",
       "1  549e992a42      sooo sad i will miss you here in san diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text  \n",
       "0  I`d have responded, if I were going  \n",
       "1                             Sooo SAD  \n",
       "2                          bullying me  \n",
       "3                       leave me alone  \n",
       "4                        Sons of ****,  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_txt=X_train['text'].apply(lambda x : tokenizer(preprocess(x), return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = X_train_txt.apply(lambda x : model(**x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "declared-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TorchTwitterRoBERTa_Pred(text = \"Good night 😊\"):\n",
    "    text = preprocess(text)\n",
    "    otpt = nlp(text)\n",
    "    NewName = {0:'roBERTa-neg', 1:'roBERTa-neu', 2:'roBERTa-pos'}\n",
    "    otpt = pd.json_normalize(otpt[0]).transpose().rename(columns=NewName).reset_index().drop([0]).drop(columns=['index'])\n",
    "    return otpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "manufactured-reception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa-neg</th>\n",
       "      <th>roBERTa-neu</th>\n",
       "      <th>roBERTa-pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00761</td>\n",
       "      <td>0.145812</td>\n",
       "      <td>0.846578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  roBERTa-neg roBERTa-neu roBERTa-pos\n",
       "1     0.00761    0.145812    0.846578"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = TorchTwitterRoBERTa_Pred()\n",
    "test\n",
    "#pd.json_normalize(dfb.Pollutants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "secure-quebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa-neg</th>\n",
       "      <th>roBERTa-neu</th>\n",
       "      <th>roBERTa-pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00761</td>\n",
       "      <td>0.145812</td>\n",
       "      <td>0.846578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  roBERTa-neg roBERTa-neu roBERTa-pos\n",
       "1     0.00761    0.145812    0.846578"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewName = {0:'roBERTa-neg', 1:'roBERTa-neu', 2:'roBERTa-pos'}\n",
    "\n",
    "#pd.DataFrame(pd.json_normalize(test).transpose().rename(columns=NewName).loc['score']).transpose()\n",
    "pd.json_normalize(test).transpose().rename(columns=NewName).reset_index().drop([0]).drop(columns=['index'])\n",
    "#.rename(columns=['roBERTa-neg', 'roBERTa-neu', 'roBERTa-pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "test= X_train.head()['text'].apply(lambda x : TorchTwitterRoBERTa_Pred(x))\n",
    "pd.DataFrame(test).apply(pd.Series.explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "permanent-darwin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0          0\n",
       "1         -1\n",
       "2         -1\n",
       "3         -1\n",
       "4         -1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ancient-basement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00118703, 0.0127858 , 0.9860271 ], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TorchTwitterRoBERTa_Pred(X_test['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "indian-trinidad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00760987, 0.14581203, 0.8465782 ], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TorchTwitterRoBERTa_Pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acting-firewall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.8466\n",
      "2) neutral 0.1458\n",
      "3) negative 0.0076\n"
     ]
    }
   ],
   "source": [
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "optical-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clTwitterroBERTa(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X[['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos']] =  X[self.field].apply(lambda x : TorchTwitterRoBERTa_Pred(x)).apply(pd.Series)\n",
    "        \n",
    "        #self.res[['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos']] =  X[self.field].apply(lambda x : TorchTwitterRoBERTa_Pred(x)).apply(pd.Series)\n",
    "        return X[['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos']]\n",
    "        #return self.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "verified-bearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sophisticated-omega",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-07e261927672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTorchTwitterRoBERTa_Pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2111\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0motypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                 res = tuple([array(x, copy=False, subok=True, dtype=t)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "np.vectorize(TorchTwitterRoBERTa_Pred)(X_train['text'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "individual-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "roBERTa_pipe=Pipeline([\n",
    "                     ('roBERTa', clTwitterroBERTa(field='text'))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "danish-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.805913</td>\n",
       "      <td>0.129099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917538</td>\n",
       "      <td>0.067550</td>\n",
       "      <td>0.014911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924613</td>\n",
       "      <td>0.070741</td>\n",
       "      <td>0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.783082</td>\n",
       "      <td>0.192980</td>\n",
       "      <td>0.023938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>0.212678</td>\n",
       "      <td>0.016557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "0     0.064988     0.805913     0.129099\n",
       "1     0.917538     0.067550     0.014911\n",
       "2     0.924613     0.070741     0.004646\n",
       "3     0.783082     0.192980     0.023938\n",
       "4     0.770765     0.212678     0.016557"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essai=roBERTa_pipe.transform(X_train.head())\n",
    "essai.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "surprising-welcome",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-65b36e0a06f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0messai\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroBERTa_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-304c8c393438>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTorchTwitterRoBERTa_Pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#self.res[['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos']] =  X[self.field].apply(lambda x : TorchTwitterRoBERTa_Pred(x)).apply(pd.Series)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4133\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4134\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4135\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-304c8c393438>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTorchTwitterRoBERTa_Pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#self.res[['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos']] =  X[self.field].apply(lambda x : TorchTwitterRoBERTa_Pred(x)).apply(pd.Series)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-4071612aaec4>\u001b[0m in \u001b[0;36mTorchTwitterRoBERTa_Pred\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#otpt = pd.DataFrame([scores], columns=['roBERTa_neg','roBERTa_neu', 'roBERTa_pos'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0motpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;31m# compute in log space for numerical stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0ma_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2731\u001b[0m     \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m     \"\"\"\n\u001b[0;32m-> 2733\u001b[0;31m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[1;32m   2734\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[1;32m     72\u001b[0m                   if v is not np._NoValue}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "essai=roBERTa_pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "distinguished-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "detailed-defendant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19231</th>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>0.977140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19232</th>\n",
       "      <td>0.019524</td>\n",
       "      <td>0.321748</td>\n",
       "      <td>0.658728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19233</th>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.646879</td>\n",
       "      <td>0.336376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19234</th>\n",
       "      <td>0.738128</td>\n",
       "      <td>0.234858</td>\n",
       "      <td>0.027013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19235</th>\n",
       "      <td>0.505228</td>\n",
       "      <td>0.461052</td>\n",
       "      <td>0.033720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "19231     0.001322     0.021538     0.977140\n",
       "19232     0.019524     0.321748     0.658728\n",
       "19233     0.016745     0.646879     0.336376\n",
       "19234     0.738128     0.234858     0.027013\n",
       "19235     0.505228     0.461052     0.033720"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essai.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "further-machinery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAEXCAYAAAC5wBJrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAArQElEQVR4nO3dfbxVZZnw8d8VoECCIvCYiQlPYYMoIYJipmM2KWqpZQk+li9pVOqk6VTmzCRZOc4M5oSWhsmkjSWGLzFl+ZakmRSgRCoWqCioKaKCmC8g1/PHXpw2eM46G84+b5zf9/M5n7PXve51r2uttQ9c+973uldkJpIkSZIa95b2DkCSJEnqyEyYJUmSpBImzJIkSVIJE2ZJkiSphAmzJEmSVMKEWZIkSSphwix1ARHxYEQc2N5xtKeI+EhELI2I1RGxZ3vHsyWJiCUR8Q/tHUdHFhHnRsT32zsOSZvHhFnq5BpLViLixIj4zfrlzByembOaaWdwRGREdG+lUNvbZOD0zNwmM+9vaWPFuXq5SMCfi4gfR8R2VetnRcSrxfr1P/9brDswItYVZS9FxJ8i4qRiXXX9dRHxStXycS2NuyMrzsuy9o6jpRo7jsy8IDNPaYdYNvi3QNLmMWGW1CY6QCK+C/BgLRU3Idb3ZOY2wP8F+gGTNlq/PkFf//PhqnVPFdv2Bb4AXBER766uDzwBfLiq7Joa49pidYD3kaQuyIRZ6gKqe6EjYu+ImBsRqyLimYj4VlHtruL3i0Vv5r4R8ZaI+JeIeDwino2IqyNi26p2jy/WrYiIf91oP5MiYkZE/E9ErAJOLPZ9b0S8GBFPR8SlEbFVVXsZEadGxKKi5/XrEfHOiPhtEe911fU3OsZGY42IrSNiNdAN+ENEPNLE9hkRp0XEImBRUfbpiFgcEc9HxMyIeHtj22bmKmAmsFvtV6Vh28zMm4HngRFN1Wvu3JVslxHx+Yh4tOgJ/8+IeEuxrsnrGxE9i2u3otjnnIjYoWRXYyLioYh4ISL+OyJ6Fu08EBENHxQiokcRxwbDYiLircAvgLdX9ai/vYn30Q8i4htV227Qo1tsd31ELI+IxyLi8yXn57Ai7pci4smI+KeqdR+KiPnF8f82IkZUrVsSEf8UEQsiYmVETC/OWdlx/E+x7fpvc06KyjChFyLisxExpmjvxYi4dKM4PxURC4u6t0TELhtd488WfzcvRsR3omIYcDmwbxHHiyXXT1IJE2ap6/k28O3M7Au8E7iuKD+g+L1d0Zt5L3Bi8fN+Kr2o2wCXAkTEbsB3geOAHYFtgZ022teRwAxgO+Aa4A0qvakDgH2BDwCnbrTNIcBewFjgS8BU4BPAzsDuwLFNHFejsWbma0VvLVR6hN/Z5JmBo4B9gN0i4iDg34BjiuN7HLi2sY0iol+x7eySthtVJK1HUDkni0uq1nLumvIRYDQwiso1+VRRfiJNXF/gBCrXdGegP/BZ4JWSfRxH5dq9E9gV+Jei/Goq12+9w4CnNx4Wk5kvA4dS9LwXP08Vqzd+HzWp+DDwv8AfqLwfPwCcGRGHNLHJlcBnMrMPlffXr4p29gSmAZ8pjv97wMyI2Lpq22OAccAQKh92TmzmODa2DzAUGA/8F/DPwD8Aw4FjIuLvi1iOBM4FPgoMBO4GfrxRWx8CxhRxHAMckpkLqVy3e4s4tmsiDknNMGGWtgw3FT1LLxa9SN8tqbsGeFdEDMjM1ZlZluQdB3wrMx/NzNXAV4AJUfla/GPA/2bmbzLzdeCrQG60/b2ZeVNmrsvMVzJzXmbOzsy1mbmEShLy9xtt8x+ZuSozHwQeAG4t9r+SSs9dUzfslcVaq3/LzOcz85WivWmZeV9mvla0t29EDK6qf19xvp8D3lEcT7Up1dclIr5ete7txbavADcCZ5WNra7x3DXl34vjeoJKYrb+Q0fZOVtDJVF8V2a+Uex/Vck+Ls3MpZn5PPDNqn38D3BYRPQtlj8J/LDGuNfb4H3UTN0xwMDMPD8zX8/MR4ErgAlN1F9D5QNS38x8ITPvK8onAt/LzN8Vx38V8BqVD3LrTcnMp4pj/l9g5CYe19cz89XMvBV4GfhxZj6bmU9SSYrXv9c/S+W9uTAz1wIXACOre5mBCzPzxeIa37kZsUgqYcIsbRmOyszt1v9Q3vN4MpUewIeLr9k/VFL37VR6Vtd7HOgO7FCsW7p+RWb+FVix0fZLqxciYteI+FlE/KX4ev0CKj2m1Z6pev1KI8vb0LiyWGtVHe8G7RUJ5Qo27EUfVZzvnsBlwN3rhyIUPl99XTLzX6vWPVVs2xeYAhxUFliN566W43q8OLY3HSMbnrMfArcA10bEUxHxHxHRY1P3UfSu3gMcHZWbIg+lmV7iZtpuzi4UH0aqPkCeS9Pvg6Op9Ho/HhG/joh9q9o5e6N2duZv5w7gL1Wv/0rT782m1Ppe3wX4dlUczwPBhu/FlsYiqYQJs9TFZOaizDwW+D/AvwMzinGXG/cOAzxF5T/r9d4BrKXyH/vTwKD1KyKiF5UeyQ12t9HyZcDDwNBiSMi5VP7jr4eyWGtVHe8G7RXnqD/w5Js2ylwDfJ/KV/O7b8L+KHqvvwzsERFHlVRtybnbuer1O6gcG5Scs8xck5lfy8zdgPdS+cr/+M3YB8BVVIZlfJxKb/GbzmGhsfdgY+UvA72rlt9W9Xop8NhGH1T6ZOZhjTacOSczj6Ty93ATfxuitBT45kbt9M7MjYdCbMpxbK6lVIaNVMfSKzN/2w6xSF2SCbPUxUTEJyJiYGauA14sitcBy4vf/7eq+o+BL0TEkIjYhkqv5vTia+EZwIcj4r1RuflsEs0ncH2AVcDqiPg74HN1OqzmYt3c9k6KiJHFuNULgN8VwyE2EBHdgJOo9Ao+uqk7Koa0XERlWEtTWnLuvhgR/SJiZ+AMYHpR3uQ5i4j3R8QexbGtojJ0YV3JPk6LiEERsT2VsbjTq9bdRGX89BlUxjQ35Rmgf1TdWNqE+VSGeWwfEW8Dzqxa93vgpYj4ckT0iohuEbF7RIzZuJGI2CoijouIbYsPPauqjvEK4LMRsU9xA91bI+LwiOjTTGybchy1uhz4SkQML+LeNiI+XuO2zwCDooYbRCU1zYRZ6nrGAQ9GZeaIbwMTivHFf6Uy9vSe4qvfsVRuevohlRk0HgNeBf4RoBhj/I9UboR7GlgNPEtlnGdT/gn4f8BLVBKS6SV1N1WTsW6OzLwd+FfgeirH907ePA72D8V5fIHKTXIfKcazrndpbDiv8rxm4n9HVM0osZGWnLufAvOoJJo/p3Kj2/p9NnXO3kblQ9EqYCHwa8rHHv8IuJXKB4ZHgIZZLIpxx9dT6YG/oakGMvNhKkn8o8V7sNFZSYo4/gAsKfbZcC4y8w0qveEji2N6jkrvf1PJ6yeBJcUwl89SGddNZs4FPk3lJsgXqNyQeWJTsW/mcdQkM2+k8m3QtUWcD1AZ2lKLX1GZTvEvEfFcS+KQurLI9NsaSS1X9FC+SGXIwGPtHI4KEZFUrknZDBxtEcdXgV0z8xPNVpakDsYeZkmbLSI+HBG9i/G9k4E/Uun1kxoUwzROpjJFoCR1OibMklriSCo3dz1FZT7ZCenXVm0qIvbfaNhHw097xwaVh79QuWntF5l5V3P1JakjckiGJEmSVMIeZkmSJKnEpjwBq80NGDAgBw8e3N5hSJIkaQs3b9685zJzYGPrOnTCPHjwYObOndveYUiSJGkLFxGPN7XOIRmSJElSCRNmSZIkqYQJsyRJklSiQ49hlqSOaM2aNSxbtoxXX321vUPplHr27MmgQYPo0aNHe4ciSTUxYZakTbRs2TL69OnD4MGDiYj2DqdTyUxWrFjBsmXLGDJkSHuHI0k1cUiGJG2iV199lf79+5ssb4aIoH///vbOS+pUTJglaTOYLG8+z52kzsaEWZIkSSrhGGZJaqGp86bWtb2Je01stk63bt3YY489WLt2LcOGDeOqq66id+/eNe/jqaee4vOf/zwzZsxg/vz5PPXUUxx22GEAzJw5k4ceeohzzjlns49BkrYkJsxNmVrf/wCZ2Px/gJJUq169ejF//nwAjjvuOC6//HLOOuusmrd/+9vfzowZMwCYP38+c+fObUiYjzjiCI444oi6xyxJnZVDMiSpk9t///1ZvHgxzz//PEcddRQjRoxg7NixLFiwAIBf//rXjBw5kpEjR7Lnnnvy0ksvsWTJEnbffXdef/11vvrVrzJ9+nRGjhzJ9OnT+cEPfsDpp5/OypUr2WWXXVi3bh0AL7/8MjvvvDNr1qzhkUceYdy4cey1117sv//+PPzww+15CiSpVZkwS1IntnbtWn7xi1+wxx57cN5557HnnnuyYMECLrjgAo4//ngAJk+ezHe+8x3mz5/P3XffTa9evRq232qrrTj//PMZP3488+fPZ/z48Q3rtt12W0aOHMmvf/1rAH72s59xyCGH0KNHDyZOnMgll1zCvHnzmDx5MqeeemrbHrgktSGHZEhSJ/TKK68wcuRIoNLDfPLJJ7PPPvtw/fXXA3DQQQexYsUKVq1axX777cdZZ53Fcccdx0c/+lEGDRpU837Gjx/P9OnTef/738+1117LqaeeyurVq/ntb3/Lxz/+8YZ6r732Wl2PT5I6EhNmSeqEqscwN+ecc87h8MMP5+abb2a//fbjlltuoWfPnjVte8QRR3Duuefy/PPPM2/ePA466CBefvlltttuu5r3L0mdnUMyJGkLsf/++3PNNdcAMGvWLAYMGEDfvn155JFH2GOPPfjyl7/MmDFj3jTeuE+fPrz00kuNtrnNNtswZswYzjjjDD70oQ/RrVs3+vbty5AhQ/jJT34CVJ7e94c//KF1D06S2pE9zJLUQrVMA9cWJk2axKc+9SlGjBhB7969ueqqqwD4r//6L+68807e8pa3MHz4cA499FCefvrphu3e//73c+GFFzJy5Ei+8pWvvKnd8ePH8/GPf5xZs2Y1lF1zzTV87nOf4xvf+AZr1qxhwoQJvOc972n1Y5Sk9hCZ2d4xNGn06NE5d+7c9tm508pJasLChQsZNmxYe4fRqXkOJXU0ETEvM0c3ts4hGZIkSVKJZhPmiOgZEb+PiD9ExIMR8bWifEhE/C4iFkfE9IjYqijfulheXKwfXNXWV4ryP0XEIa12VJIkSVKd1NLD/BpwUGa+BxgJjIuIscC/Axdn5ruAF4CTi/onAy8U5RcX9YiI3YAJwHBgHPDdiOhWx2ORJEmS6q7ZhDkrVheLPYqfBA4CZhTlVwFHFa+PLJYp1n8gIqIovzYzX8vMx4DFwN71OAhJkiSptdQ0hjkiukXEfOBZ4DbgEeDFzFxbVFkG7FS83glYClCsXwn0ry5vZBtJkiSpQ6opYc7MNzJzJDCISq/w37VWQBExMSLmRsTc5cuXt9ZuJEmSpJps0jzMmfliRNwJ7AtsFxHdi17kQcCTRbUngZ2BZRHRHdgWWFFVvl71NtX7mApMhcq0cpt2OJLUDtphGsqI4KyzzuKiiy4CYPLkyaxevZpJkybVNZQLLriAc889t2H5ve99L7/97W/rug9J6uhqmSVjYERsV7zuBXwQWAjcCXysqHYC8NPi9cximWL9r7Iy2fNMYEIxi8YQYCjw+zodhyR1KVtvvTU33HADzz33XKvu54ILLthg2WRZUldUy5CMHYE7I2IBMAe4LTN/BnwZOCsiFlMZo3xlUf9KoH9RfhZwDkBmPghcBzwE/BI4LTPfqOfBSFJX0b17dyZOnMjFF1/8pnXLly/n6KOPZsyYMYwZM4Z77rmnofyDH/wgw4cP55RTTmGXXXZpSLiPOuoo9tprL4YPH87Uosf8nHPO4ZVXXmHkyJEcd9xxQOVR2QATJkzg5z//ecM+TzzxRGbMmMEbb7zBF7/4RcaMGcOIESP43ve+16rnQZLaQi2zZCzIzD0zc0Rm7p6Z5xflj2bm3pn5rsz8eGa+VpS/Wiy/q1j/aFVb38zMd2bmuzPzF613WJK05TvttNO45pprWLly5QblZ5xxBl/4wheYM2cO119/PaeccgoAX/va1zjooIN48MEH+djHPsYTTzzRsM20adOYN28ec+fOZcqUKaxYsYILL7yQXr16MX/+fK655poN9jF+/Hiuu+46AF5//XXuuOMODj/8cK688kq23XZb5syZw5w5c7jiiit47LHHWvlMSFLr2qQxzJKkjqNv374cf/zxTJkyhV69ejWU33777Tz00EMNy6tWrWL16tX85je/4cYbbwRg3Lhx9OvXr6HOlClTGtYtXbqURYsW0b9//yb3feihh3LGGWfw2muv8ctf/pIDDjiAXr16ceutt7JgwQJmzKjMOrpy5UoWLVrEkCFD6nrsktSWTJglqRM788wzGTVqFCeddFJD2bp165g9ezY9e/asqY1Zs2Zx++23c++999K7d28OPPBAXn311dJtevbsyYEHHsgtt9zC9OnTmTBhAgCZySWXXMIhh/gwV0lbjpqmlZMkdUzbb789xxxzDFdeeWVD2cEHH8wll1zSsDx//nwA9ttvv4ZhFLfeeisvvPACUOkF7tevH7179+bhhx9m9uzZDdv26NGDNWvWNLrv8ePH89///d/cfffdjBs3DoBDDjmEyy67rGGbP//5z7z88sv1O2BJagf2MEtSS9UwDVxrOvvss7n00ksblqdMmcJpp53GiBEjWLt2LQcccACXX3455513Hsceeyw//OEP2XfffXnb295Gnz59GDduHJdffjnDhg3j3e9+N2PHjm1oa+LEiYwYMYJRo0a9aRzzwQcfzCc/+UmOPPJIttpqKwBOOeUUlixZwqhRo8hMBg4cyE033dQm50GSWktUZnzrmEaPHp1z585tn523w7yqkjqHhQsXMmzYsPYOY5O99tprdOvWje7du3Pvvffyuc99rqH3ua111nMoacsVEfMyc3Rj6+xhlqQu4oknnuCYY45h3bp1bLXVVlxxxRXtHZIkdQomzJLURQwdOpT777+/vcOQpE7Hm/4kSZKkEibMkiRJUgkTZkmSJKmECbMkSZJUwpv+JKmF2mMWyojgrLPO4qKLLgJg8uTJrF69mkmTJm3y/l588UV+9KMfceqpp27ytoMHD2bu3LkMGDBgk7eVpM7CHmZJ6oS23nprbrjhBp577rkWt/Xiiy/y3e9+t9F1a9eubXH7ktTZmTBLUifUvXt3Jk6cyMUXX/ymdcuXL+foo49mzJgxjBkzhnvuuQeASZMmMXny5IZ6u+++O0uWLOGcc87hkUceYeTIkXzxi19k1qxZ7L///hxxxBHstttuABx11FHstddeDB8+nKn17lKXpA7OIRmS1Emtf/z1l770pQ3KzzjjDL7whS/wvve9jyeeeIJDDjmEhQsXNtnOhRdeyAMPPNDw1L9Zs2Zx33338cADDzBkyBAApk2bxvbbb88rr7zCmDFjOProo+nfv3+rHZskdSQmzJLUSfXt25fjjz+eKVOm0KtXr4by22+/nYceeqhhedWqVaxevXqT2t57770bkmWAKVOmcOONNwKwdOlSFi1aZMIsqcswYZakTuzMM89k1KhRnHTSSQ1l69atY/bs2fTs2XODut27d2fdunUNy6+++mqT7b71rW9teD1r1ixuv/127r33Xnr37s2BBx5Yuq0kbWkcwyxJndj222/PMcccw5VXXtlQdvDBB3PJJZc0LK8fajF48GDuu+8+AO677z4ee+wxAPr06cNLL73U5D5WrlxJv3796N27Nw8//DCzZ89uhSORpI7LHmZJaqFapoFrTWeffTaXXnppw/KUKVMaxjevXbuWAw44gMsvv5yjjz6aq6++muHDh7PPPvuw6667AtC/f3/2228/dt99dw499FAOP/zwDdofN24cl19+OcOGDePd7343Y8eObdPjk6T2FpnZ3jE0afTo0Tl37tz22Xl7TKwqqVNYuHAhw4YNa+8wOjXPoaSOJiLmZeboxtbZwyxJkqTNMnVe/aeZnLhXx+tkdAyzJEmSVMKEWZI2Q0ceztbRee4kdTYmzJK0iXr27MmKFStM/DZDZrJixYo3TXknSR1Zs2OYI2Jn4GpgByCBqZn57YiYBHwaWF5UPTczby62+QpwMvAG8PnMvKUoHwd8G+gGfD8zL6zv4UhS6xs0aBDLli1j+fLlzVfWm/Ts2ZNBgwa1dxiSVLNabvpbC5ydmfdFRB9gXkTcVqy7ODMnV1eOiN2ACcBw4O3A7RGxa7H6O8AHgWXAnIiYmZkPIUmdSI8ePTZ4Cp4kacvWbMKcmU8DTxevX4qIhcBOJZscCVybma8Bj0XEYmDvYt3izHwUICKuLeqaMEuSJKnD2qQxzBExGNgT+F1RdHpELIiIaRHRryjbCVhatdmyoqyp8o33MTEi5kbEXL/ulCRJUnurOWGOiG2A64EzM3MVcBnwTmAklR7oi+oRUGZOzczRmTl64MCB9WhSkiRJ2mw1PbgkInpQSZavycwbADLzmar1VwA/KxafBHau2nxQUUZJuSRJktQhNdvDHBEBXAkszMxvVZXvWFXtI8ADxeuZwISI2DoihgBDgd8Dc4ChETEkIraicmPgzPochiRJktQ6aulh3g/4JPDHiJhflJ0LHBsRI6lMNbcE+AxAZj4YEddRuZlvLXBaZr4BEBGnA7dQmVZuWmY+WLcjkSRJklpBLbNk/AaIRlbdXLLNN4FvNlJ+c9l2kiRJUkfjk/4kSZKkEibMkiRJUgkTZkmSJKmECbMkSZJUwoRZkiRJKmHCLEmSJJUwYZYkSZJKmDBLkiRJJUyYJUmSpBImzJIkSVIJE2ZJkiSphAmzJEmSVMKEWZIkSSphwixJkiSVMGGWJEmSSpgwS5IkSSVMmCVJkqQSJsySJElSCRNmSZIkqYQJsyRJklTChFmSJEkqYcIsSZIklTBhliRJkko0mzBHxM4RcWdEPBQRD0bEGUX59hFxW0QsKn73K8ojIqZExOKIWBARo6raOqGovygiTmi9w5IkSZLqo5Ye5rXA2Zm5GzAWOC0idgPOAe7IzKHAHcUywKHA0OJnInAZVBJs4DxgH2Bv4Lz1SbYkSZLUUTWbMGfm05l5X/H6JWAhsBNwJHBVUe0q4Kji9ZHA1VkxG9guInYEDgFuy8znM/MF4DZgXD0PRpIkSaq3TRrDHBGDgT2B3wE7ZObTxaq/ADsUr3cCllZttqwoa6p8431MjIi5ETF3+fLlmxKeJEmSVHc1J8wRsQ1wPXBmZq6qXpeZCWQ9AsrMqZk5OjNHDxw4sB5NSpIkSZutpoQ5InpQSZavycwbiuJniqEWFL+fLcqfBHau2nxQUdZUuSRJktRh1TJLRgBXAgsz81tVq2YC62e6OAH4aVX58cVsGWOBlcXQjVuAgyOiX3Gz38FFmSRJktRhda+hzn7AJ4E/RsT8ouxc4ELguog4GXgcOKZYdzNwGLAY+CtwEkBmPh8RXwfmFPXOz8zn63EQkiRJUmtpNmHOzN8A0cTqDzRSP4HTmmhrGjBtUwKUJEmS2pNP+pMkSZJKmDBLkiRJJUyYJUmSpBImzJIkSVIJE2ZJkiSphAmzJEmSVMKEWZIkSSphwixJkiSVMGGWJEmSSpgwS5IkSSVMmCVJkqQSJsySJElSCRNmSZIkqYQJsyRJklTChFmSJEkqYcIsSZIklTBhliRJkkqYMEuSJEklTJglSZKkEibMkiRJUgkTZkmSJKmECbMkSZJUwoRZkiRJKmHCLEmSJJVoNmGOiGkR8WxEPFBVNikinoyI+cXPYVXrvhIRiyPiTxFxSFX5uKJscUScU/9DkSRJkuqvlh7mHwDjGim/ODNHFj83A0TEbsAEYHixzXcjoltEdAO+AxwK7AYcW9SVJEmSOrTuzVXIzLsiYnCN7R0JXJuZrwGPRcRiYO9i3eLMfBQgIq4t6j606SFLkiRJbaclY5hPj4gFxZCNfkXZTsDSqjrLirKmyt8kIiZGxNyImLt8+fIWhCdJkiS13OYmzJcB7wRGAk8DF9UroMycmpmjM3P0wIED69WsJEmStFmaHZLRmMx8Zv3riLgC+Fmx+CSwc1XVQUUZJeWSJElSh7VZPcwRsWPV4keA9TNozAQmRMTWETEEGAr8HpgDDI2IIRGxFZUbA2duftiSJElS22i2hzkifgwcCAyIiGXAecCBETESSGAJ8BmAzHwwIq6jcjPfWuC0zHyjaOd04BagGzAtMx+s98FIkiRJ9VbLLBnHNlJ8ZUn9bwLfbKT8ZuDmTYpOkiRJamc+6U+SJEkqYcIsSZIklTBhliRJkkqYMEuSJEklTJglSZKkEibMkiRJUgkTZkmSJKmECbMkSZJUwoRZkiRJKmHCLEmSJJUwYZYkSZJKmDBLkiRJJUyYJUmSpBImzJIkSVIJE2ZJkiSphAmzJEmSVMKEWZIkSSphwixJkiSVMGGWJEmSSpgwS5IkSSVMmCVJkqQSJsySJElSie7tHUBXMnVqfdubOLG+7UmSJOnNmu1hjohpEfFsRDxQVbZ9RNwWEYuK3/2K8oiIKRGxOCIWRMSoqm1OKOoviogTWudwJEmSpPqqZUjGD4BxG5WdA9yRmUOBO4plgEOBocXPROAyqCTYwHnAPsDewHnrk2xJkiSpI2s2Yc7Mu4DnNyo+EriqeH0VcFRV+dVZMRvYLiJ2BA4BbsvM5zPzBeA23pyES5IkSR3O5t70t0NmPl28/guwQ/F6J2BpVb1lRVlT5W8SERMjYm5EzF2+fPlmhidJkiTVR4tnycjMBLIOsaxvb2pmjs7M0QMHDqxXs5IkSdJm2dyE+ZliqAXF72eL8ieBnavqDSrKmiqXJEmSOrTNTZhnAutnujgB+GlV+fHFbBljgZXF0I1bgIMjol9xs9/BRZkkSZLUoTU7D3NE/Bg4EBgQEcuozHZxIXBdRJwMPA4cU1S/GTgMWAz8FTgJIDOfj4ivA3OKeudn5sY3EkqSJEkdTrMJc2Ye28SqDzRSN4HTmmhnGjBtk6JrR1Pv+rv2DkGSJEkdgI/GliRJkkqYMEuSJEklTJglSZKkEibMkiRJUgkTZkmSJKmECbMkSZJUotlp5dRxTZ1a3/YmTqxve5IkSVsCe5glSZKkEvYwt5W77qpvewccUN/2JEmS1Ch7mCVJkqQSJsySJElSCYdkSJIkdRFT59V5xoAuwh5mSZIkqYQJsyRJklTChFmSJEkqYcIsSZIklfCmPzXwyYGSJElvZg+zJEmSVMKEWZIkSSphwixJkiSVMGGWJEmSSpgwS5IkSSVMmCVJkqQSLUqYI2JJRPwxIuZHxNyibPuIuC0iFhW/+xXlERFTImJxRCyIiFH1OABJkiSpNdWjh/n9mTkyM0cXy+cAd2TmUOCOYhngUGBo8TMRuKwO+5YkSZJaVWsMyTgSuKp4fRVwVFX51VkxG9guInZshf1LkiRJddPShDmBWyNiXkSsf67bDpn5dPH6L8AOxeudgKVV2y4ryiRJkqQOq6WPxn5fZj4ZEf8HuC0iHq5emZkZEbkpDRaJ90SAd7zjHS0MT5IkSWqZFvUwZ+aTxe9ngRuBvYFn1g+1KH4/W1R/Eti5avNBRdnGbU7NzNGZOXrgwIEtCU+SJElqsc3uYY6ItwJvycyXitcHA+cDM4ETgAuL3z8tNpkJnB4R1wL7ACurhm5oCzR1av3bnDix+TqSJEn11JIhGTsAN0bE+nZ+lJm/jIg5wHURcTLwOHBMUf9m4DBgMfBX4KQW7FuSJElqE5udMGfmo8B7GilfAXygkfIETtvc/UmSJEntoaU3/UmSJKmVTJ3XCuMbtcl8NLYkSZJUwoRZkiRJKuGQDHUq9Z55w1k3JElSc0yYO6u77qp/mwccUP82JUmSOjmHZEiSJEklTJglSZKkEg7JUJfmmGhJktQce5glSZKkEibMkiRJUgmHZEiSJNWJT+bbMpkwS3XkmGhJkrY8DsmQJEmSStjDrL+p98NQfBBKi9W7xxrstZak9Rw+oVrZwyxJkiSVsIdZkiR1CvYIq72YMEtqkdYYNlJPDkGRJLWUCbNaj2OiO6SOnuBK2nLYI7zlu+uGv6trewd89OG6tlcvJsyStmhd8QOCveqSGlPv5LYrMWGWpC1MV/yQUG9+6NDmMCHdcpkwq/NwiIekNtIZPnTUO6mfOhXuerzO/85SvwSyNb6qN8FVrUyY1XXVOwEHk3BpC1L/5LG+7vrn9o6gbZncqj2ZMHdif35+UV3b23X7oXVtDzpHjJLaXkdPRiWpmglziXonex1dZzjeDh/jTfWN7y97DuWAXbper3W9k6mOfg5NHiWpY2vzhDkixgHfBroB38/MC9s6BqmzeNv9i/jz/R38Q0Kd/WXP+n+LYEIqSWqJNk2YI6Ib8B3gg8AyYE5EzMzMh9oyDkkd19vq/AGhNRJwSVLX0tY9zHsDizPzUYCIuBY4EjBhltQq6p2AS5Ja0UfbO4DGtXXCvBOwtGp5GbBPdYWImAisnyxndUT8qY1iqzYAeK4d9qu25XXuOrzWXYfXuuvwWm+JfgGf4TPVJW15nXdpakWHu+kvM6cC7ToDZkTMzczR7RmDWp/XuevwWncdXuuuw2vdNXSU6/yWNt7fk8DOVcuDijJJkiSpQ2rrhHkOMDQihkTEVsAEYGYbxyBJkiTVrE2HZGTm2og4HbiFyrRy0zLzwbaMoUad4KGoqgOvc9fhte46vNZdh9e6a+gQ1zkys71jkCRJkjqsth6SIUmSJHUqJsySJElSiS6bMEfEuIj4U0QsjohzGlm/dURML9b/LiIGt0OYqoMarvVZEfFQRCyIiDsiosl5GNWxNXetq+odHREZEe0+VZE2Ty3XOiKOKf62H4yIH7V1jGq5Gv79fkdE3BkR9xf/hh/WHnGq5SJiWkQ8GxEPNLE+ImJK8V5YEBGj2jK+LpkwVz2i+1BgN+DYiNhto2onAy9k5ruAi4F/b9soVQ81Xuv7gdGZOQKYAfxH20apeqjxWhMRfYAzgN+1bYSql1qudUQMBb4C7JeZw4Ez2zpOtUyNf9P/AlyXmXtSmXnru20bperoB8C4kvWHAkOLn4nAZW0QU4MumTBT9YjuzHwdWP+I7mpHAlcVr2cAH4iIaMMYVR/NXuvMvDMz/1oszqYyP7g6n1r+rgG+TuUD8KttGZzqqpZr/WngO5n5AkBmPtvGMarlarnOCfQtXm8LPNWG8amOMvMu4PmSKkcCV2fFbGC7iNixbaLruglzY4/o3qmpOpm5FlgJ9G+T6FRPtVzraicDv2jViNRamr3WxVd4O2fmz9syMNVdLX/XuwK7RsQ9ETE7Isp6rtQx1XKdJwGfiIhlwM3AP7ZNaGoHm/r/eV11uEdjS+0lIj4BjAb+vr1jUf1FxFuAbwEntnMoahvdqXx1eyCVb43uiog9MvPF9gxKdXcs8IPMvCgi9gV+GBG7Z+a69g5MW5au2sNcyyO6G+pERHcqX/WsaJPoVE81PY49Iv4B+GfgiMx8rY1iU301d637ALsDsyJiCTAWmOmNf51SLX/Xy4CZmbkmMx8D/kwlgVbnUct1Phm4DiAz7wV6AgPaJDq1tZr+P28tXTVhruUR3TOBE4rXHwN+lT7lpTNq9lpHxJ7A96gky45z7LxKr3VmrszMAZk5ODMHUxmvfkRmzm2fcNUCtfwbfhOV3mUiYgCVIRqPtmGMarlarvMTwAcAImIYlYR5eZtGqbYyEzi+mC1jLLAyM59uq513ySEZTT2iOyLOB+Zm5kzgSipf7SymMgh9QvtFrM1V47X+T2Ab4CfFfZ1PZOYR7Ra0NkuN11pbgBqv9S3AwRHxEPAG8MXM9FvCTqTG63w2cEVEfIHKDYAn2rnVOUXEj6l8yB1QjEk/D+gBkJmXUxmjfhiwGPgrcFKbxuf7SpIkSWpaVx2SIUmSJNXEhFmSJEkqYcIsSZIklTBhliRJkkqYMEuSJEklTJglSZKkEl1yHmZJ6igiYjCwEPgTEMDLwEmZ+aeIOBD4KfBY1Sb/lJm3R8QbwB+p/Dv+GPBJKvPVbg1sD/Tib0/BOiozl7T2sUjSlsqEWZLaQFSeihOZua6R1Y9k5sii3meAc/nbk0bvzswPNbLNK1XbXAWclpn7FMsnAqMz8/S6HoQkdVEOyZCkVhIRgyPiTxFxNfAAcGVEPBARf4yI8U1s1hd4YRN3dS+wUxMxfDgifhcR90fE7RGxQ0m8kyLihxFxb0QsiohPF+UREf+5cewRsWNE3BUR84t1+29i3JLUKdjDLEmtayiV3uKdgM8C7wEGAHMi4q6izjsjYj7QB+gN7FO1/f7FuvWOzsxH1i9ERDfgA8CVTez/N8DYzMyIOAX4EpXHCTdlBDAWeCtwf0T8HNgXGNlI7P8PuCUzv1nE0bukXUnqtEyYJal1PZ6ZsyPiYuDHmfkG8ExE/BoYAyxgwyEZ44GpwLhi+6aGZPQqEumdqIyBvq2J/Q8CpkfEjsBWbDgeujE/zcxXgFci4k5gb+B9TcQ+B5gWET2AmzJzfjNtS1Kn5JAMSWpdL29i/ZnAATXUWz+GeRcqNwue1kS9S4BLM3MP4DNAz2bazWaW/7Yi864i1ieBH0TE8TXELUmdjgmzJLWNu4HxEdEtIgZSSTR/30i99wGPNFLeqMz8K/B54OyIaOxbw23522wZJzSyfmNHRkTPiOgPHEilF7nR2CNiF+CZzLwC+D4wqta4JakzcUiGJLWNG6mMBf4DlV7bL2XmX4pp5daPYQ7gdeCUqu02HsP8jcycUd1wZt4fEQuAY4EfbrTfScBPIuIF4FfAkGbiXADcSWWs8tcz86mIaCr2E4AvRsQaYDVgD7OkLVJkNvltmySpC4mIScDqzJzc3rFIUkfikAxJkiSphEMyJKmLiYiTgDM2Kr4nM5u6cVCSujSHZEiSJEklHJIhSZIklTBhliRJkkqYMEuSJEklTJglSZKkEv8feLEo3So71OAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for var in ['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos']:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    sns.distplot(essai[(y_train==1)['sentiment']][var], bins=30, kde=False, \n",
    "                 color='green', label='Positive')\n",
    "    sns.distplot(essai[(y_train==-1)['sentiment']][var], bins=30, kde=False, \n",
    "                 color='red', label='Negative')\n",
    "    sns.distplot(essai[(y_train==0)['sentiment']][var], bins=30, kde=False, \n",
    "                 color='blue', label='Neutral')\n",
    "    plt.legend()\n",
    "    plt.title(f'Histogram of {var} by true sentiment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "limiting-budget",
   "metadata": {},
   "source": [
    "## 1) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-beach",
   "metadata": {},
   "source": [
    "On commence par définir une fonction générique qui sera en capacité d'ajuster, optimiser et logger dans MLFlow les résultats de pipelines qui seront produits pour chaque essai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "framed-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPipelineMlFlow(xpName, pipeline, X_train, y_train, X_test, y_test, fixed_params={}, opti=False, iterable_params={}):\n",
    "    \"\"\"\n",
    "    Fonction générique permettant d'entrainer et d'optimiser un pipeline sklearn\n",
    "    Les paramètres et résultats sont stockés dans MLFlow\n",
    "    \"\"\"\n",
    "  \n",
    "    with mlflow.start_run(run_name=xpName):\n",
    "        \n",
    "        start_time = time.monotonic()  \n",
    "        \n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        \n",
    "        # fit pipeline\n",
    "        pipeline.set_params(**fixed_params)\n",
    "        if not opti:\n",
    "            search = pipeline\n",
    "        else:\n",
    "            search = RandomizedSearchCV(pipeline, iterable_params)\n",
    "        search.fit(X_train, y_train)\n",
    "                \n",
    "        # get params\n",
    "        # params_to_log = pipeline.get_params() #select initial params PB : can lead to greater than 250 charac limit\n",
    "        params_to_log = fixed_params #select initial params\n",
    "        if opti:\n",
    "            params_to_log.update(search.best_params_) #update for optimal solution\n",
    "        mlflow.log_params(params_to_log)\n",
    "        \n",
    "        \n",
    "        # Evaluate metrics\n",
    "        y_pred=search.predict(X_test)\n",
    "        (f1_test, cr_test) = eval_metrics(y_test, y_pred)\n",
    "        \n",
    "        # Print out metrics\n",
    "        print(xpName)\n",
    "        print(\"  f1_test: %s\" % f1_test)\n",
    "        print(\"  CR_test: %s\" % cr_test)\n",
    "\n",
    "        mlflow.log_metrics({\"f1_test\": f1_test})\n",
    "        mlflow.sklearn.log_model(pipeline, xpName)\n",
    "        \n",
    "        end_time = time.monotonic()\n",
    "        elapsed_time = timedelta(seconds=end_time - start_time)\n",
    "        print('elapsed time :', elapsed_time)\n",
    "        mlflow.set_tag(key=\"elapsed_time\", value=elapsed_time)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "editorial-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_state_params(pipe, seed):\n",
    "    \"\"\"Crée un dictionnaire constitué de tous les paramètres 'random_state' d'un pipe et leur assigne une valeur unique\"\"\"\n",
    "    rs = re.findall(r\"[a-zA-Z\\_]+_random_state\", ' '.join(list(pipe.get_params().keys())))\n",
    "    rs=dict.fromkeys(rs, seed)\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-sector",
   "metadata": {},
   "source": [
    "La cellule suivante permet de créer des étapes de sélection de colonnes dans les Data Frame en entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "geographic-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[[self.field]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "clean-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "attractive-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function so that we could reuse later\n",
    "def plot_cm(y_test, y_pred, target_names=[-1, 0, 1], \n",
    "            figsize=(5,3)):\n",
    "    \"\"\"Create a labelled confusion matrix plot.\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='BuGn', cbar=False, \n",
    "                ax=ax)\n",
    "    ax.set_title('Confusion matrix')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_xticklabels(target_names)\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_yticklabels(target_names, \n",
    "                       fontdict={'verticalalignment': 'center'});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-imperial",
   "metadata": {},
   "source": [
    "## roBERTa RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "grateful-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "roBERTa_RF_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('roBERTa', clTwitterroBERTa(field='text')),\n",
    "        (\"classifier\", RandomForestClassifier(n_jobs=-1))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "loving-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "roBERTa_RF_Pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('roBERTa', roBERTa_pipe),\n",
    "        (\"classifier\", RandomForestClassifier(n_jobs=-1))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "handled-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__random_state': 42}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state_params(roBERTa_RF_Pipe, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "professional-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-613e99fcc862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainPipelineMlFlow(xpName=\"roBERTa - RF\", \n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroBERTa_RF_Pipe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     fixed_params=random_state_params(roBERTa_RF_Pipe, random_state))\n",
      "\u001b[0;32m<ipython-input-271-8913bbf1274a>\u001b[0m in \u001b[0;36mtrainPipelineMlFlow\u001b[0;34m(xpName, pipeline, X_train, y_train, X_test, y_test, fixed_params, opti, iterable_params)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# get params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \"\"\"\n\u001b[1;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 return last_step.fit(Xt, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-268-d9a6c38e828f>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTorchTwitterRoBERTa_Pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#X[['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos']] =  X[self.field].apply(lambda x : TorchTwitterRoBERTa_Pred(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-268-d9a6c38e828f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTorchTwitterRoBERTa_Pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#X[['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos']] =  X[self.field].apply(lambda x : TorchTwitterRoBERTa_Pred(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-4071612aaec4>\u001b[0m in \u001b[0;36mTorchTwitterRoBERTa_Pred\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1156\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         )\n\u001b[0;32m--> 815\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    816\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 )\n\u001b[1;32m    507\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    509\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainPipelineMlFlow(xpName=\"roBERTa - RF\", \n",
    "                    pipeline=roBERTa_RF_Pipe, \n",
    "                    X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, \n",
    "                    fixed_params=random_state_params(roBERTa_RF_Pipe, random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "flying-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_roBERTa_RF = roBERTa_RF_Pipe.predict(X_train)\n",
    "y_test_pred_roBERTa_RF = roBERTa_RF_Pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "comparative-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_roBERTa= roBERTa_pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "severe-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_roBERTa= roBERTa_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "concerned-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_roBERTa.to_pickle('/mnt/data/interim/X_train_roBERTa.plk')\n",
    "X_test_roBERTa.to_pickle('/mnt/data/interim/X_test_roBERTa.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "functional-cologne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041864</td>\n",
       "      <td>0.867173</td>\n",
       "      <td>0.090963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.986027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.920724</td>\n",
       "      <td>0.073319</td>\n",
       "      <td>0.005957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.013607</td>\n",
       "      <td>0.983983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.027338</td>\n",
       "      <td>0.969399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.990900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.909208</td>\n",
       "      <td>0.078257</td>\n",
       "      <td>0.012535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.857621</td>\n",
       "      <td>0.127331</td>\n",
       "      <td>0.015048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.203005</td>\n",
       "      <td>0.742505</td>\n",
       "      <td>0.054490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.151973</td>\n",
       "      <td>0.842662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "0     0.041864     0.867173     0.090963\n",
       "1     0.001187     0.012786     0.986027\n",
       "2     0.920724     0.073319     0.005957\n",
       "3     0.002410     0.013607     0.983983\n",
       "4     0.003263     0.027338     0.969399\n",
       "5     0.001562     0.007538     0.990900\n",
       "6     0.909208     0.078257     0.012535\n",
       "7     0.857621     0.127331     0.015048\n",
       "8     0.203005     0.742505     0.054490\n",
       "9     0.005365     0.151973     0.842662"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_roBERTa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "annoying-typing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0          0\n",
       "1          1\n",
       "2         -1\n",
       "3          1\n",
       "4          1"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "animated-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_roBERTa.to_pickle('/mnt/data/interim/X_test_roBERTa.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "other-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train_pred_roBERTa_RF).to_pickle('/mnt/data/interim/y_train_pred_roBERTa_RF.plk')\n",
    "pd.DataFrame(y_test_pred_roBERTa_RF).to_pickle('/mnt/data/interim/y_test_pred_roBERTa_RF.plk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "little-transaction",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_roBERTa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-321-9593140ade67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_roBERTa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_roBERTa' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_roBERTa[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bronze-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_score_roBERTa_RF=pd.DataFrame(roBERTa_RF_pipeline['classifier'].predict_proba(X_train_roBERTa_RF), columns=['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "grave-ranch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19231</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19232</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19233</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19234</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19235</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "19231         0.00         0.00         1.00\n",
       "19232         0.13         0.17         0.70\n",
       "19233         0.00         0.99         0.01\n",
       "19234         0.20         0.80         0.00\n",
       "19235         0.25         0.75         0.00"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_score_roBERTa_RF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "statewide-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_score_roBERTa_RF=pd.DataFrame(roBERTa_RF_pipeline['classifier'].predict_proba(X_test_roBERTa), columns=['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "abstract-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_score_roBERTa_RF.to_pickle('/mnt/data/interim/y_train_score_roBERTa_RF.plk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "cultural-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_score_roBERTa_RF.to_pickle('/mnt/data/interim/y_test_score_roBERTa_RF.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "hawaiian-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_roBERTa_RF=pd.DataFrame(roBERTa_RF_pipeline['classifier'].predict(X_test_roBERTa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "proud-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2 -1\n",
       "3  1\n",
       "4  1"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_roBERTa_RF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "modified-facility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2   -1\n",
       "3    1\n",
       "4    1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_test_pred_roBERTa_RF[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "spare-advancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0          0\n",
       "1          1\n",
       "2         -1\n",
       "3          1\n",
       "4          1"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "individual-muscle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAADgCAYAAAB7EB+KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcHElEQVR4nO3deZyO9f7H8dfHIOsYjH3fJ9pPR46KaFXKUpKlhcqhUsIhJ51oQUmHiorIkqVfp3RQ4RzZKlkSKoQSyZgxhrGX4fv74/6aRseMMWbmmuX9fDzuh7mu7/e+rs91P8z7/l7LXJc55xAREcgXdAEiItmFAlFExFMgioh4CkQREU+BKCLiKRBFRDwFomQKMytsZrPNLMHM3juH5XQys/kZWVtQzOxqM/s+6DokZabrEPM2M+sI9AaigAPAGuB559xn57jcu4GeQGPnXOK51pndmZkD6jjntgRdi6SfRoh5mJn1BkYCQ4ByQFVgDNAqAxZfDdiUF8IwLcwsf9A1SBo45/TKgy+gBHAQaJdKn/MIBeZO/xoJnOfbrgF2AH2AWCAa6OLbBgO/Acf8Ou4HBgHvJFt2dcAB+f30fcCPhEapW4FOyeZ/lux9jYGVQIL/t3GytkXAs8DnfjnzgcgUtu1k/f2S1d8auBnYBMQDf0/WvyGwDNjn+74GFPRtS/y2HPLb2z7Z8vsDu4ApJ+f599Ty67jMT1cEdgPXBP1/Iy+/NELMu/4CFAJmptLnSaARcAlwMaFQGJisvTyhYK1EKPRGm1lJ59zThEad7zrnijnnxqdWiJkVBV4BWjjnihMKvTWn6VcK+Mj3LQ28DHxkZqWTdesIdAHKAgWBvqmsujyhz6AS8A9gHNAZ+BNwNfCUmdXwfY8DjwORhD67a4GHAJxzTXyfi/32vpts+aUIjZa7JV+xc+4HQmH5jpkVAd4GJjnnFqVSr2QyBWLeVRqIc6nv0nYCnnHOxTrndhMa+d2drP2Ybz/mnPuY0OioXjrrOQFcYGaFnXPRzrnvTtPnFmCzc26Kcy7ROTcd2AjcmqzP2865Tc65I8D/EQrzlBwjdLz0GDCDUNiNcs4d8OtfT+iLAOfcV865L/16fwLeBJqmYZueds796us5hXNuHLAFWA5UIPQFJAFSIOZde4DIMxzbqghsSza9zc9LWsYfAvUwUOxsC3HOHSK0m9kdiDazj8wsKg31nKypUrLpXWdRzx7n3HH/88nAiknWfuTk+82srpnNMbNdZraf0Ag4MpVlA+x2zh09Q59xwAXAq865X8/QVzKZAjHvWgb8Sui4WUp2EtrdO6mqn5ceh4AiyabLJ290zs1zzl1PaKS0kVBQnKmekzX9ks6azsbrhOqq45wLB/4O2Bnek+olHGZWjNBx2fHAIH9IQAKkQMyjnHMJhI6bjTaz1mZWxMwKmFkLM3vRd5sODDSzMmYW6fu/k85VrgGamFlVMysBDDjZYGblzKyVP5b4K6Fd7xOnWcbHQF0z62hm+c2sPVAfmJPOms5GcWA/cNCPXnv8oT0GqHmWyxwFrHLOPUDo2Ogb51ylnBMFYh7mnBtB6BrEgYTOcP4MPAJ86Ls8B6wC1gHfAKv9vPSs6z/Au35ZX3FqiOXzdewkdOa1Kf8bODjn9gAtCZ3Z3kPoDHFL51xcemo6S30JnbA5QGj0+u4f2gcBk8xsn5ndeaaFmVkr4CZ+387ewGVm1inDKpazpguzRUQ8jRBFRDwFooiIp0AUEfEUiCIingJRRMTLtnfgqDX8ep3+zmIzH5gadAl5Tt3wM/2xi2S0QmH5UrygXiNEERFPgSgi4ikQRUQ8BaKIiKdAFBHxFIgiIp4CUUTEUyCKiHgKRBERT4EoIuIpEEVEPAWiiIinQBQR8RSIIiKeAlFExFMgioh4CkQREU+BKCLiKRBFRDwFooiIp0AUEfGy7VP3sqsaJSvzym0Dk6arlCjPyM8nEXNgD49eeTe1S1el7ZSefBOzCYDbzm/Ogw3vTOofVaYGt01+iA2xP2R57TlVXEwMrw1+nn3x8ZgZ17W+jVvat0tqnz11BpNfHc34ubMJj4hImr9l/QaefLAHvZ59mr80bxZA5bnL8ePH6dCuHWXLleW1199gx44d9O/Th4R9+zi/QX2GDHuBAgULBl3mOVEgnqWte3dw66TuAOSzfHzRYzrzN39O4fyFeOjDwTx3Q69T+s/a8CmzNnwKQN3I6rzRZrDC8CyFhYVxz6MPUzOqHkcOHab/ffdzUcPLqVKjBnExMaxdsYLI8uVOec/x48d5Z/QbXNzwzwFVnftMnTKFmrVqcvDgQQBGjRhB53vvocXNt/DsoEHM/OB97ryrQ8BVnpss32U2s2JZvc7M0rjapWzfF83O/bH8EL+drXt3pNr/1vOb89GGRVlTXC5SMjKSmlH1AChctAiVqlcnPjYOgIkjX6XzIw9hnPqo3bnvvU+jZk0JLxmR1eXmSjG7drF08WLa3H4HAM45Viz/kutvuBGA21q34tMFC4IsMUMEcQxxfQDrzBQto65h9oaFae5/S1RTZm9Me3/5X7E7o9m6aRN1LqjPyiVLKVWmDNXr1D6lz57Y3SxfvIQb2rYOpshc6MVhQ3m8b1/y5QtFxr59+yhePJz8+UM7meXKlSc2JibIEjNEpuwym1nvlJqAXDFCLJAvP9fW+gvDl4xPU/+LK0Rx9NivbIr7KXMLy8WOHD7MSwMG0qXXo4SFhfHBxCkMfOXl/+k3ceQrdH64R9Ivr5ybxYsWUqpUKeo3aMDKFSuCLidTZdYxxCHAcCDxNG0p/i81s25AN4DItlGEN6qcOdVlgKY1/8x3sVvYc3hfmvqf7WhSTpWYmMiIAQO5+sbruaJZU7Zt+YHY6Gj+1rkLAHt276bfvfczdMJYftjwPSMHDgJgf0ICXy/7krCwMBo2bRLgFuRca1Z/zaKFC/lsyRJ+/fU3Dh06yItDhnDgwH4SExPJnz8/MTG7KFuu3JkXls1lViCuBj50zn31xwYzeyClNznnxgJjAWoNv95lUm0Z4taoZmkOOMO4uV5T7pr+eCZXlTs553j9+WFUql6dWzveBUC12rUY/8nspD4PtW7HsInjCI+IYMzM/0ua/9ozz/OnqxorDM/BY71781jv0E7fyhUrmPT2BIYOH07fXr34z/x5tLj5FmZ9+G+aNW8ecKXnLrP2KboA25LPMLPy/sfLM2mdWaZwgUJcWf1PzNu0NGneDXWu5LPu07i04vm8dftzvH3H0KS2hlUuJPrAbn5O2BVEuTnexrXfsOSTeXy76iv63t2Fvnd3YfUXy4IuK8/r1acPUyZNouWNN5Kwb1/SCZeczJzLmoGYma12zl2W1v7ZfYSYG818YGrQJeQ5dcMjgy4hzykUls9SasvKo84pFiEikh1kZSCOy8J1iYictSwLROfcmKxal4hIeuhCLRERT4EoIuIpEEVEPAWiiIinQBQR8RSIIiKeAlFExFMgioh4CkQREU+BKCLiKRBFRDwFooiIp0AUEfEUiCIingJRRMRTIIqIeApEERFPgSgi4ikQRUQ8BaKIiJdlz2U+W0tjtmXPwnKxJp2vDLqEPGfT++uDLiHPqRMeni2eyywikq0pEEVEPAWiiIinQBQR8RSIIiKeAlFExFMgioh4CkQREU+BKCLiKRBFRDwFooiIp0AUEfEUiCIiXv6UGszsVSDFO8445x7NlIpERAKSYiACq7KsChGRbCDFQHTOTcrKQkREgpbaCBEAMysD9AfqA4VOznfONc/EukREslxaTqpMBTYANYDBwE/AykysSUQkEGkJxNLOufHAMefcYudcV0CjQxHJdc64ywwc8/9Gm9ktwE6gVOaVJCISjLQE4nNmVgLoA7wKhAOPZ2pVIiIBOGMgOufm+B8TgGaZW46ISHDScpb5bU5zgbY/lpjnxMfEMn7IcPbH78XMaHLrzVzXrg3bN//AOyNGcey338gXFkanx3tSs34Uhw4cYOKwEcT+Ek2BggXp8kRvKtWsEfRm5DiPtrmfB1t0wMwY9/E0Rs0czzP39qVV4xs54U4Quy+O+4b3JnpPDBHFSjChzwhqVazG0d9+peuIPnz30/dBb0KOsnvXLl4eNIh98fEYcGObNrTq0IEDCQm88Pe/ExMdTbkKFXhi6FCKhYez8JNPeH/yZJxzFC5ShIeeeIKadesGvRln7YzPZTaz25NNFgLaADsz+y9VsutzmffF7SFhTzzV6tXh6OHDPPvAwzw8ZBAzXnmd6+9sy4WNGrJu2QrmTv8/+r3yEu+NGct5hQtzW5e7id62nan/fI2+I18MejNOK7s+l7lB9XrM+PtoGvZsyW/HjjF36Dt0HzWA2H1xHDh8EICerbtSv1odeowawIsPDuTgkUM8884/qVelFqN7Ps91/e4KeCtOL7s+lzk+Lo74uDhqR0Vx+NAhet1zDwOHD+e/c+ZQPDycdvfdx3sTJ3LwwAG69OzJhrVrqVKjBsXCw1n1+edMGzeOlydODHozTuucnsvsnHs/2WsqcCdweUYWmJNERJamWr06ABQqUoQK1aqyd3ccZsaRQ4cBOHLoEBGRpQHY+dN2oi67BIAK1aqyZ1cMCfF7A6k9pzq/am2Wb1zDkV+PcvzEcRav+5K2V7VICkOAooUKc/LLvX61Ony65nMAvv/5B6qXq0zZiMhAas+pSkVGUjsqCoAiRYtSpXp19uzezfLFi7m2ZUsArm3Zki8XLQLg/Isvplh4OABRF15IXGxsIHWfq/Tc3KEOUPZMncwsysz6m9kr/tXfzM5Px/qyrbjoXWzfvIWa9aNo37MH/3p9HH+7vSPvjRnL7d1CRxSq1K7J6iWfAfDj+o3siYlh7+7dQZad43z70/dcfWFDShWPoPB5hbi5YXOqlKkIwHNd+rF96go6NW/DPya9BMDaH9fT9qoWAPy53iVUK1eZymUqBFZ/Thezcyc/fv899Ro0YF98PKUiQ18uJUuXZl98/P/0n//vf3N548ZZXWaGOGMgmtkBM9t/8gXMJvSXK6m9pz8wAzBghX8ZMN3Mnkjlfd3MbJWZrZo1ZdrZbEeWO3r4CGOeeob2PXtQuGhRFv17Nu0f6c7w96fR/pHuTHzhZQBadGrP4YOHGNy1O59+8G+q1qlNvnxhAVefs2zcvoUX3h3D/GHTmDvkHdb88B3HTxwHYODbL1K1U0OmfjqTR1p1AWDYjNFEFAvn6zfm0bN1F77e8m1Sfzk7Rw4fZkj//jzYuzdFihU7pc3MwE7d+1y3ahXzZ83ivkceycoyM0xazjIXT8dy7wcaOOeOJZ9pZi8D3wHDUljXWGAsZN9jiACJiYm8/tQzNLq+OX9qehUAy+b+hw6PPgTA5c2aMOnFfwJQuGhRug7oC4Bzjifa30OZiuWDKTwHmzB3BhPmzgDg+a792bE7+pT2qQtm8vHzkxk0eQQHDh+k60t9ktq2TlnGj9Hbs7Te3CAxMZEh/ftzzU030bh56G8xIkqVIj4ujlKRkcTHxRFRsmRS/62bN/PKc88xeNQowiMiAqr63KRlhLggLfP+4ARQ8TTzK/i2HMs5x6QXXqZCtarc0P6OpPklSpfm+zXrANi4eg1lK4c2//CBgyQeC30vLJ3zCXUvvpDCRYtmfeE5XJmI0DHZKmUq0vbKFkz79ENqV/r9bH2rxjey8ecfAChRNJwC+QsA8ECLjiz5ZvkpxxvlzJxzjHr2WapUr06bTp2S5l/RpAkL5oSuxFswZw5XNG0KQOyuXQzp148+gwdTqVq1QGrOCKndD7EQUASINLOShHZ5IXRhdqUzLLcXsMDMNgM/+3lVgdpAzhxLe1u++Y5l8/5LpZo1GNy1OwBtHuzKvf0eZ/orYzhx/AQFChbgnr/1AiB623YmDBkOZlSsXo37nugdYPU51/v/GEvp8JIcS0zk4deeJOHQfsb3eYl6lWtywjm2xeyg+6gBQOgkzKR+I3HO8d22Tdw/om/A1ec869euZeHHH1O9dm16duwIwD0PP8wd997LsAEDmD9rFmXLl+eJoUMBmPHWW+xPSGDMCy8AEJY/PyMnTw6s/vRK8bIbM3uMULBVBH7h90DcD4xzzr2W6oLN8gEN+T08fwFWOufSdDAnO+8y51bZ9bKb3Cy7XnaTm6V22U1q90McBYwys57OuVfPdqXOuRPAl2f7PhGRoKTlspsTZhZxcsLMSprZQ5lXkohIMNISiA865/adnHDO7QUezLSKREQCkpZADDP7/WIjMwsDCmZeSSIiwUjL7b/mAu+a2Zt++q/AJ5lXkohIMNISiP2BbkB3P70O0JXFIpLrpOXmDieA5YSepdKQ0OMDNmRuWSIiWS+1C7PrAh38Kw54F8A5p5vEikiulNou80ZgKdDSObcFwMz06AARybVS22VuC0QDC81snJldy+9/rSIikuukGIjOuQ+dc3cBUcBCQn/GV9bMXjezG7KoPhGRLJOWkyqHnHPTnHO3ApWBrznD/RBFRHKis7pjtnNur3NurHPu2swqSEQkKOl5hICISK6kQBQR8RSIIiKeAlFExFMgioh4CkQREU+BKCLiKRBFRDwFooiIl+JjSIN29PiJ7FlYLrZp/56gS8hzLhmkP/rKaidGrUvxJjUaIYqIeApEERFPgSgi4ikQRUQ8BaKIiKdAFBHxFIgiIp4CUUTEUyCKiHgKRBERT4EoIuIpEEVEPAWiiIinQBQR8RSIIiKeAlFExFMgioh4CkQREU+BKCLiKRBFRDwFooiIp0AUEfHyB11AbnD8+HE6tGtH2XJlee31N5g+dSpTJ0/m55+3s+jzLyhZsmTQJeZocTExvDb4OfbF78UMrmt9G7e0vzOpffbU6Ux+dTTj584hPCKCpXPn8+GUqTgchYsU4cF+fahep06AW5Az9bqmM/c3aosDvtm5ma7TnuKtDoO5vEoDjp1IZOW2b/jru8+SeCIRgFFt+9Oi/tUcPnaULlOf4usdG4LdgHTQCDEDTJ0yhZq1aiZNX3Lppbw5YQIVK1YMsKrcIywsjHsefYSRM95hyFtjmfevD/h561YgFJZrV6wksny5pP5lK1Zg8Ouv8vLUydzR5V7eHPpiUKXnWBVLlKVnk078eUQHLhrWlrB8+bjrspuY9tVHnD/kNi4a1pZCBQrxwF/aAtCi/lXULlONus+15K8znmFMu4EBb0H6KBDPUcyuXSxdvJg2t9+RNO/8+vWpVKlSgFXlLiUjI6kZVQ+AwkWLUKl6deJj4wCYOPJVOj/SA+P3Z4/Xu+hCioWHA1Dnggbs2b0764vOBfLnC6NwgfMIyxdGkYKF2Jmwm0/Wf5bUvnL7N1SOCH0RtbqgGVNWzgZg+bZ1RBQuTvnwyEDqPhcKxHP04rChPN63L/ny6aPMCrE7o9m6aRN1LqjPyiVLKVUmMtXd4U9nz+HSRo2ysMLcYWdCLCMWTmLboPnsfHYBCUcO8p/vlyW158+Xn86X38rcDZ8DUDGiLD/v25XUviMhhkolymZ53ecqy3+LzaxLVq8zsyxetJBSpUpRv0GDoEvJE44cPsxLA56kS6/HCAsL44OJk2nf7YEU+3/71Wo+nfURnR/pkYVV5g4RhYtz2wXNqDm4BZWeuo6iBQvT6fJbktrHtHuSpT98xWc/rg6wyowXxLBmcEoNZtbNzFaZ2arx48ZmZU3psmb11yxauJAW111L/z59WLl8OQP69Qu6rFwpMTGREQMGcvWNN3BFs6bs2vELsdHR/K3zfTzU+g727N5Nv3u7snfPHgC2bd7CG0OG0W/4UIqXKBFw9TnPdfUa8VP8DuIO7SXxRCIz1y2gcY1LAPjHTd2JLFaS3h8OT+q/c18sVSLKJ01XLlGOXxJis7rsc5YpZ5nNbF1KTUC5FNpwzo0FxgIcPX7CZUJpGeqx3r15rHdvAFauWMGktycw9EUdwM9ozjlef34olapX49aOdwFQrXYtxn8yJ6nPQ63vYNjEtwiPiGD3rl0MH/AkPZ9+iopVqwZVdo62fe8urqh2EYULFOLIsaM0r3sFX23/jvsbteWGqMZcN/pBnPv9V3TWt4t4+OoOzFj9CVdUu4iEowfYtT8uwC1In8y67KYccCOw9w/zDfgik9aZbUydMoWJE8azJy6Odq1bcVWTJgx69rmgy8qxNq5dx5JP5lG1Vi363n0fAB17/JXLGv/ltP3/NX4iBxMSGDd8BBA6S/3CxPFZVW6usGLbN7y/9r989bd3STxxnK93bGDsF//i4PDlbNsbzRe9pgAwc90Cnp33Jh+vX8rN9a9m81Mfcfi3o3Sd9lTAW5A+ljzlM2yhZuOBt51zn52mbZpzruOZlpETRoi5zab9e4IuIc+5ZNC1QZeQ55wYtc5SasuUEaJz7v5U2s4YhiIiQdC1IiIingJRRMRTIIqIeApEERFPgSgi4ikQRUQ8BaKIiKdAFBHxFIgiIp4CUUTEUyCKiHgKRBERT4EoIuIpEEVEPAWiiIinQBQR8RSIIiKeAlFExFMgioh4CkQREU+BKCLiKRBFRLxMeS5zXmdm3ZxzY4OuIy/RZ571cuNnrhFi5ugWdAF5kD7zrJfrPnMFooiIp0AUEfEUiJkjVx1XySH0mWe9XPeZ66SKiIinEaKIiKdAzEBmFmVmy8zsVzPrG3Q9eYGZ3WRm35vZFjN7Iuh68gIzm2BmsWb2bdC1ZDQFYsaKBx4FXgq6kLzAzMKA0UALoD7QwczqB1tVnjARuCnoIjKDAjEDOedinXMrgWNB15JHNAS2OOd+dM79BswAWgVcU67nnFtC6Ms/11EgSk5WCfg52fQOP08kXRSIIiKeAvEcmdnDZrbGvyoGXU8e8wtQJdl0ZT9PJF0UiOfIOTfaOXeJf+0Mup48ZiVQx8xqmFlB4C5gVsA1SQ6mC7MzkJmVB1YB4cAJ4CBQ3zm3P9DCcjEzuxkYCYQBE5xzzwdbUe5nZtOBa4BIIAZ42jk3PtCiMogCUUTE0y6ziIinQBQR8RSIIiKeAlFExFMgioh4CkTJMmZ23F/A/q2ZvWdmRc5hWRPN7A7/81up3dTBzK4xs8bpWMdPZhaZ3hol51EgSlY64i9gvwD4DeievNHM8qdnoc65B5xz61Ppcg1w1oEoeY8CUYKyFKjtR29LzWwWsN7MwsxsuJmtNLN1ZvZXAAt5zd/78L9A2ZMLMrNFZna5//kmM1ttZmvNbIGZVScUvI/70enVZlbGzN7361hpZlf695Y2s/lm9p2ZvQVYFn8mErB0fSOLnAs/EmwBzPWzLgMucM5tNbNuQIJz7s9mdh7wuZnNBy4F6hG672E5YD0w4Q/LLQOMA5r4ZZVyzsWb2RvAQefcS77fNOCfzrnPzKwqMA84H3ga+Mw594yZ3QLcn6kfhGQ7CkTJSoXNbI3/eSkwntCu7Arn3FY//wbgopPHB4ESQB2gCTDdOXcc2Glmn55m+Y2AJSeX5ZxL6Z591wH1zZIGgOFmVsyvo61/70dmtjd9myk5lQJRstIR59wlyWf4UDqUfBbQ0zk37w/9bs7AOvIBjZxzR09Ti+RhOoYo2c08oIeZFQAws7pmVhRYArT3xxgrAM1O894vgSZmVsO/t5SffwAonqzffKDnyQkzu8T/uATo6Oe1AEpm1EZJzqBAlOzmLULHB1f7hxi9SWhPZiaw2bdNBpb98Y3Oud1AN+ADM1sLvOubZgNtTp5UIfTcm8v9SZv1/H62ezChQP2O0K7z9kzaRsmmdLcbERFPI0QREU+BKCLiKRBFRDwFooiIp0AUEfEUiCIingJRRMRTIIqIeP8PpXxoa0VhRHkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm(y_test['sentiment'], y_test_pred_roBERTa_RF[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "talented-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "(f1_test, cr_test) = eval_metrics(y_test['sentiment'], y_test_pred_roBERTa_RF[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "trying-parts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.705164810393604"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "respiratory-lloyd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.72      0.70      1001\n",
      "           0       0.66      0.66      0.66      1430\n",
      "           1       0.77      0.74      0.76      1103\n",
      "\n",
      "    accuracy                           0.70      3534\n",
      "   macro avg       0.71      0.71      0.71      3534\n",
      "weighted avg       0.70      0.70      0.70      3534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "loose-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-breath",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-closing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-sound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-polyester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-hopkins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-carpet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-translation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-johns",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-rapid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "olympic-scottish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.805913</td>\n",
       "      <td>0.129099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>shanghai is also really exciting (precisely -...</td>\n",
       "      <td>0.917538</td>\n",
       "      <td>0.067550</td>\n",
       "      <td>0.014911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>recession hit veronique branquinho, she has to...</td>\n",
       "      <td>0.924613</td>\n",
       "      <td>0.070741</td>\n",
       "      <td>0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>0.783082</td>\n",
       "      <td>0.192980</td>\n",
       "      <td>0.023938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - i like it!!</td>\n",
       "      <td>0.770765</td>\n",
       "      <td>0.212678</td>\n",
       "      <td>0.016557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  roBERTa_neg  \\\n",
       "0  f87dea47db  last session of the day  http://twitpic.com/67ezh     0.064988   \n",
       "1  96d74cb729   shanghai is also really exciting (precisely -...     0.917538   \n",
       "2  eee518ae67  recession hit veronique branquinho, she has to...     0.924613   \n",
       "3  01082688c6                                        happy bday!     0.783082   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - i like it!!     0.770765   \n",
       "\n",
       "   roBERTa_neu  roBERTa_pos  \n",
       "0     0.805913     0.129099  \n",
       "1     0.067550     0.014911  \n",
       "2     0.070741     0.004646  \n",
       "3     0.192980     0.023938  \n",
       "4     0.212678     0.016557  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "literary-invite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0          0\n",
       "1          1\n",
       "2         -1\n",
       "3          1\n",
       "4          1"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "boxed-diamond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00118703, 0.01278579, 0.9860271 ], dtype=float32)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TorchTwitterRoBERTa_Pred(X_test['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cross-ensemble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.805913</td>\n",
       "      <td>0.129099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917538</td>\n",
       "      <td>0.067550</td>\n",
       "      <td>0.014911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924613</td>\n",
       "      <td>0.070741</td>\n",
       "      <td>0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.783082</td>\n",
       "      <td>0.192980</td>\n",
       "      <td>0.023938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>0.212678</td>\n",
       "      <td>0.016557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "0     0.064988     0.805913     0.129099\n",
       "1     0.917538     0.067550     0.014911\n",
       "2     0.924613     0.070741     0.004646\n",
       "3     0.783082     0.192980     0.023938\n",
       "4     0.770765     0.212678     0.016557"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_roBERTa_RF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "supposed-wings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.04186411, 0.8671732, 0.09096259]\n",
       "1    [0.0011870284, 0.0127857905, 0.9860271]\n",
       "2       [0.9207242, 0.07331903, 0.005956579]\n",
       "3     [0.0024100505, 0.013606693, 0.9839832]\n",
       "4      [0.003262817, 0.027337728, 0.9693994]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= X_test['text'][0:5].apply(lambda x : TorchTwitterRoBERTa_Pred(x))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "dense-symphony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041864</td>\n",
       "      <td>0.867173</td>\n",
       "      <td>0.090963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.986027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.920724</td>\n",
       "      <td>0.073319</td>\n",
       "      <td>0.005957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.013607</td>\n",
       "      <td>0.983983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.027338</td>\n",
       "      <td>0.969399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "0     0.041864     0.867173     0.090963\n",
       "1     0.001187     0.012786     0.986027\n",
       "2     0.920724     0.073319     0.005957\n",
       "3     0.002410     0.013607     0.983983\n",
       "4     0.003263     0.027338     0.969399"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roBERTa_pipe.transform(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "automotive-trace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041864</td>\n",
       "      <td>0.867173</td>\n",
       "      <td>0.090963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.986027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.920724</td>\n",
       "      <td>0.073319</td>\n",
       "      <td>0.005957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.013607</td>\n",
       "      <td>0.983983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.027338</td>\n",
       "      <td>0.969399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "0     0.041864     0.867173     0.090963\n",
       "1     0.001187     0.012786     0.986027\n",
       "2     0.920724     0.073319     0.005957\n",
       "3     0.002410     0.013607     0.983983\n",
       "4     0.003263     0.027338     0.969399"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roBERTa_RF_Pipe['roBERTa'].transform(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-cooler",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-atlantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-mystery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-intersection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "outer-insider",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-c5b9cd66c1f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroBERTa_RF_pipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-133-e058f36d340e>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTorchTwitterRoBERTa_Pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-e058f36d340e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTorchTwitterRoBERTa_Pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-4071612aaec4>\u001b[0m in \u001b[0;36mTorchTwitterRoBERTa_Pred\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1156\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         )\n\u001b[0;32m--> 815\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    816\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 )\n\u001b[1;32m    507\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    509\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "roBERTa_RF_pipeline['roBERTa'].transform(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-manitoba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-advantage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "classified-handling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "0         0.00         1.00          0.0\n",
       "1         0.89         0.11          0.0\n",
       "2         0.97         0.03          0.0\n",
       "3         0.96         0.04          0.0\n",
       "4         0.91         0.09          0.0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_score_roBERTa_RF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "floppy-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1 -1\n",
       "2 -1\n",
       "3 -1\n",
       "4 -1"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(roBERTa_RF_pipeline['classifier'].predict(X_test_roBERTa_RF)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "underlying-stamp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.805913</td>\n",
       "      <td>0.129099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>shanghai is also really exciting (precisely -...</td>\n",
       "      <td>0.917538</td>\n",
       "      <td>0.067550</td>\n",
       "      <td>0.014911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>recession hit veronique branquinho, she has to...</td>\n",
       "      <td>0.924613</td>\n",
       "      <td>0.070741</td>\n",
       "      <td>0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>0.783082</td>\n",
       "      <td>0.192980</td>\n",
       "      <td>0.023938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - i like it!!</td>\n",
       "      <td>0.770765</td>\n",
       "      <td>0.212678</td>\n",
       "      <td>0.016557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  roBERTa_neg  \\\n",
       "0  f87dea47db  last session of the day  http://twitpic.com/67ezh     0.064988   \n",
       "1  96d74cb729   shanghai is also really exciting (precisely -...     0.917538   \n",
       "2  eee518ae67  recession hit veronique branquinho, she has to...     0.924613   \n",
       "3  01082688c6                                        happy bday!     0.783082   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - i like it!!     0.770765   \n",
       "\n",
       "   roBERTa_neu  roBERTa_pos  \n",
       "0     0.805913     0.129099  \n",
       "1     0.067550     0.014911  \n",
       "2     0.070741     0.004646  \n",
       "3     0.192980     0.023938  \n",
       "4     0.212678     0.016557  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "looking-possible",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-c5b9cd66c1f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroBERTa_RF_pipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-133-e058f36d340e>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTorchTwitterRoBERTa_Pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-e058f36d340e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTorchTwitterRoBERTa_Pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roBERTa_neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roBERTa_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-4071612aaec4>\u001b[0m in \u001b[0;36mTorchTwitterRoBERTa_Pred\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1156\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         )\n\u001b[0;32m--> 815\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    816\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 )\n\u001b[1;32m    507\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    509\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "roBERTa_RF_pipeline['roBERTa'].transform(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-tuition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-lesbian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-baghdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-corruption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-seafood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-conversion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-spanking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-findings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-andorra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "nearby-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "technological-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dietary-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bi = label_binarize(y_test['sentiment'], classes=[-1, 0, 1])\n",
    "n_classes = y_test_bi.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "pressing-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0          0\n",
       "1          1\n",
       "2         -1\n",
       "3          1\n",
       "4          1"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "passing-biography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bi[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "increasing-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bi[:, i], y_test_score_roBERTa_RF[['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos'][i]])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "sealed-separate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3534, 3)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_score_roBERTa_RF.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "negative-somewhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10602,)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_score_roBERTa_RF.to_numpy().ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "indie-serum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3534,)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.to_numpy().ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "removed-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame(roBERTa_RF_pipeline['classifier'].predict_proba(X_test_roBERTa_RF), columns=['roBERTa_neg', 'roBERTa_neu', 'roBERTa_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "shared-victory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "0         0.00         1.00          0.0\n",
       "1         0.89         0.11          0.0\n",
       "2         0.97         0.03          0.0\n",
       "3         0.96         0.04          0.0\n",
       "4         0.91         0.09          0.0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "distant-victim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roBERTa_neg</th>\n",
       "      <th>roBERTa_neu</th>\n",
       "      <th>roBERTa_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.805913</td>\n",
       "      <td>0.129099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917538</td>\n",
       "      <td>0.067550</td>\n",
       "      <td>0.014911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924613</td>\n",
       "      <td>0.070741</td>\n",
       "      <td>0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.783082</td>\n",
       "      <td>0.192980</td>\n",
       "      <td>0.023938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>0.212678</td>\n",
       "      <td>0.016557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roBERTa_neg  roBERTa_neu  roBERTa_pos\n",
       "0     0.064988     0.805913     0.129099\n",
       "1     0.917538     0.067550     0.014911\n",
       "2     0.924613     0.070741     0.004646\n",
       "3     0.783082     0.192980     0.023938\n",
       "4     0.770765     0.212678     0.016557"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_roBERTa_RF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-artist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-techno",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-accreditation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-spell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "certified-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(np.where(abs(y_test_bi.ravel())>0.5,1,0), y_test_score_roBERTa_RF.to_numpy().ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "realistic-indication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "formed-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yellowbrick\n",
      "  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (3.3.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (0.24.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (1.6.0)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (0.10.0)\n",
      "Requirement already satisfied: numpy<1.20,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from cycler>=0.10.0->yellowbrick) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (8.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20->yellowbrick) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20->yellowbrick) (1.0.1)\n",
      "Installing collected packages: yellowbrick\n",
      "Successfully installed yellowbrick-1.3.post1\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "featured-slovak",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-7d01bba95b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mROCAUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "visualizer = ROCAUC(model, classes=[\"win\", \"loss\", \"draw\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "intermediate-combining",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-7ef35da23503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_score_roBERTa_RF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \"\"\"\n\u001b[0;32m--> 913\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    914\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    689\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    690\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 691\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test['sentiment'], y_test_score_roBERTa_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-vector",
   "metadata": {},
   "source": [
    "# fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
